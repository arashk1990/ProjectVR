{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for lstm network development. data preparation for lstm can be found in preprocess/seqdata.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arash/anaconda3/envs/gpusupport/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/arash/anaconda3/envs/gpusupport/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/arash/anaconda3/envs/gpusupport/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/arash/anaconda3/envs/gpusupport/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/arash/anaconda3/envs/gpusupport/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/arash/anaconda3/envs/gpusupport/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/arash/anaconda3/envs/gpusupport/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/arash/anaconda3/envs/gpusupport/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/arash/anaconda3/envs/gpusupport/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/arash/anaconda3/envs/gpusupport/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/arash/anaconda3/envs/gpusupport/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/arash/anaconda3/envs/gpusupport/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from math import ceil, sqrt\n",
    "from numba import cuda \n",
    "import random\n",
    "import glob,os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pdb\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Embedding, Masking, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.externals import joblib\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import talos as ta\n",
    "from talos.utils.gpu_utils import multi_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if gpu is  available\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory before start\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/arash/ProjectVR/cleaneddata/seperateddata/inputseqtrain', 'rb') as f:\n",
    "#     inputseqtrain = pickle.load(f) \n",
    "\n",
    "# with open('/home/arash/ProjectVR/cleaneddata/seperateddata/ytrain', 'rb') as f:\n",
    "#     ytrain = pickle.load(f) \n",
    "# with open('/home/arash/ProjectVR/cleaneddata/seperateddata/inputseqTEST', 'rb') as f:\n",
    "#     inputseqTEST = pickle.load(f) \n",
    "# with open('/home/arash/ProjectVR/cleaneddata/seperateddata/ytest', 'rb') as f:\n",
    "#     ytest = pickle.load(f) \n",
    "\n",
    "folder = '/home/arash/ProjectVR/cleaneddata/seperateddata/'\n",
    "dtype = '_LW_3'   \n",
    "# TW_i_o for time seq, i sec input, o sec output length \n",
    "# LW_n for length seq, n/10 input proportion\n",
    "\n",
    "with open(f'{folder}inputseqTrain{dtype}', 'rb') as f:\n",
    "    inputseqTrain = pickle.load(f) \n",
    "    \n",
    "with open(f'{folder}inputauxTrain{dtype}', 'rb') as f:\n",
    "    inputauxTrain = pickle.load(f) \n",
    "    \n",
    "with open(f'{folder}outTrain{dtype}', 'rb') as f:\n",
    "    outTrain = pickle.load(f) \n",
    "    \n",
    "with open(f'{folder}inputseqTest{dtype}', 'rb') as f:\n",
    "    inputseqTest = pickle.load(f) \n",
    "\n",
    "with open(f'{folder}inputauxTest{dtype}', 'rb') as f:\n",
    "    inputauxTest = pickle.load(f)\n",
    "    \n",
    "with open(f'{folder}outTest{dtype}', 'rb') as f:\n",
    "    outTest = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge aux and seq in to use as input\n",
    "maxlen = max(inputseqTrain.shape[1],inputauxTrain.shape[1])\n",
    "\n",
    "inputseqTrain = pad_sequences(inputseqTrain, maxlen = maxlen,\n",
    "                              dtype='float32',value=-0.01)\n",
    "\n",
    "inputauxTrain = pad_sequences(inputauxTrain, maxlen = maxlen,\n",
    "                              dtype='float32',value=-0.01)\n",
    "\n",
    "inpTrain = np.dstack((inputseqTrain,inputauxTrain))\n",
    "\n",
    "inputseqTest = pad_sequences(inputseqTest, maxlen = maxlen,\n",
    "                              dtype='float32',value=-0.01)\n",
    "\n",
    "inputauxTest = pad_sequences(inputauxTest, maxlen = maxlen,\n",
    "                              dtype='float32',value=-0.01)\n",
    "\n",
    "inpTest = np.dstack((inputseqTest,inputauxTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Vanilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\"Llayers\" : [1,2],\n",
    "      \"nodes\" : [10,50],\n",
    "      \"batch_size\": [128],\n",
    "      \"epochs\": [200]}\n",
    "\n",
    "def VanillaLSTM(X_t,Out_t,X_val,Out_val,params):\n",
    "    n_features = X_t.shape[2] \n",
    "    n_steps_in = X_t.shape[1]\n",
    "    n_steps_out = Out_t.shape[1]\n",
    "    \n",
    "    Llayers = params['Llayers']\n",
    "    nodes = params['nodes']\n",
    "    epochs = params['epochs']\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=-0.01, input_shape=(n_steps_in, n_features)))\n",
    "    \n",
    "    for i in range(Llayers-1):\n",
    "        model.add(LSTM(nodes, activation='relu',\n",
    "                       return_sequences=True))\n",
    "        \n",
    "    model.add(LSTM(nodes, activation='relu'))\n",
    "    model.add(Dense(n_steps_out))\n",
    "\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    Out_t = Out_t[:,:,0] # 0 is index for X\n",
    "    Out_val = Out_val[:,:,0]\n",
    "    \n",
    "    start = time.time()\n",
    "    history = model.fit(X_t, Out_t,\n",
    "                        validation_data=[X_val, Out_val],\n",
    "                        epochs = epochs, verbose = 100,\n",
    "                        batch_size = batch_size)\n",
    "    end = time.time()\n",
    "\n",
    "    print (\"Finished Fitting Model. # of Epochs: %d\\n Time Taken : %d secs\"\n",
    "           % (epochs,end - start))\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scan_object = ta.Scan(x = inputseqTrain,\n",
    "                      y = outTrain, \n",
    "                      params = p,\n",
    "                      model = VanillaLSTM,\n",
    "                      val_split = 0.2,\n",
    "                      experiment_name='VLSTM_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing the results data frame\n",
    "scan_object.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the summary details\n",
    "scan_object.details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VanillaLSTM(BaseEstimator):\n",
    "    \n",
    "#     def __init__(self, nodes=50, batch_size=128,\n",
    "#                  epochs=200, Llayers=1, features=6, steps_in=0, steps_out=0\n",
    "#                  ):\n",
    "\n",
    "#         self.nodes = nodes\n",
    "#         self.batch_size = batch_size\n",
    "#         self.epochs = epochs\n",
    "#         self.Llayers= Llayers\n",
    "#         self.features = features\n",
    "#         self.steps_in = steps_in\n",
    "#         self.steps_out = steps_out\n",
    "#         self.maxXY=654.9\n",
    "#         self.minXY=650.1\n",
    "\n",
    "\n",
    "#     def create_model(self):\n",
    "#         model = Sequential()\n",
    "#         model.add(Masking(mask_value=-0.01, input_shape=(self.steps_in, self.features)))\n",
    "#         for i in range(self.Llayers-1):\n",
    "#             model.add(LSTM(self.nodes, activation='relu', return_sequences=True))\n",
    "#         model.add(LSTM(self.nodes, activation='relu'))\n",
    "#         model.add(Dense(self.steps_out))\n",
    "#         model.compile(optimizer='adam', loss='mse')\n",
    "#         return model\n",
    "    \n",
    "#     def fit(self,inputseq,out):\n",
    "#         start = time.time()\n",
    "#         X = inputseq[:,:,:self.features]\n",
    "#         out = out[:,:,0] # 0 is index for X\n",
    "#         self.model=self.create_model()\n",
    "#         self.model.fit(X, out, epochs = self.epochs, verbose = 100, batch_size = self.batch_size)\n",
    "#         end = time.time()\n",
    "#         print (\"Finished Fitting Model. # of Epochs: %d\\n Time Taken : %d secs\"\n",
    "#                % (self.epochs,end - start))\n",
    "#         return self\n",
    "    \n",
    "#     def predict(self, inputseq):\n",
    "#         X = inputseq[:,:,:self.features]\n",
    "        \n",
    "#         return self.model.predict(X)\n",
    "    \n",
    "#     def score(self,inputseq,out):\n",
    "        \n",
    "#         X = inputseq[:,:,:self.features]\n",
    "#         outpred = self.predict(X)\n",
    "#         out = out[:,:,0]\n",
    "#         outinv = np.zeros(out.shape)\n",
    "#         outpredinv = np.zeros(outpred.shape)\n",
    "#         for i in range(len(out)):\n",
    "#             pos = sum (n>=0 for n in out[i])     #position of the last actual value on y, not padded\n",
    "#             outinv[i][:pos]= out[i][:pos] * (self.maxXY-self.minXY) + self.minXY\n",
    "#             outpredinv[i][:pos] = outpred[i][:pos]* (self.maxXY-self.minXY) + self.minXY\n",
    "            \n",
    "#         rmseScore = -sqrt(mean_squared_error(outpredinv, outinv))    #negative of RMSE\n",
    "\n",
    "#         return rmseScore\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fitting Vanilla LSTM, using grid search for hypperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_features = inpTrain.shape[2] - 1\n",
    "# n_steps_in = inpTrain.shape[1]\n",
    "# n_steps_out = outTrain.shape[1]\n",
    "\n",
    "# VLmodel=VanillaLSTM(epochs=200, features=n_features,\n",
    "#                     steps_in=n_steps_in, steps_out=n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned_params = {\"Llayers\" : [1,2],\"nodes\" : [10,50]}#,\"batch_size\": [128]}\n",
    "\n",
    "#gs = GridSearchCV(VLmodel, tuned_params,cv = 8, refit= True, n_jobs=-1,verbose = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.load('/home/arash/ProjectVR/models/trainedmodels/VLSTM1.pkl',allow_pickle=True)      \n",
    "# outTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_result = gs.fit(inpTrain,outTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(f'/home/arash/ProjectVR/models/GridResults/VLSTM200_8{dtype}.npy',grid_result.cv_results_)      \n",
    "#filename: ModelnameEpochs_CV_data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestVLSTM = grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(bestVLSTM, '/home/arash/ProjectVR/models/trainedmodels/VLSTM1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestVLSTM.score(inpTest,outTest)\n",
    "\n",
    "# bestVLSTM.score(inpTest,outTest)\n",
    "\n",
    "# VLmodel.fit(inpTrain,outTrain)\n",
    "\n",
    "# VLmodel.score(inpTEST,outTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = bestVLSTM.model.history.history\n",
    "# # plot history\n",
    "# plt.plot(history['loss'], label='train')\n",
    "# #pyplot.plot(history.history['val_loss'], label='test')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lstm model with aux variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\"Llayers\" : [1,2],\n",
    "     \"Dlayers\" : [1],\n",
    "     \"nodes\" : [10,50],\n",
    "     \"batch_size\": [128], \n",
    "     \"drpout\" : [0, 0.2],\n",
    "     \"epochs\": [200]}\n",
    "\n",
    "def AuxLSTM(X_t,Out_t,X_val,Out_val,params):\n",
    "    n_features = X_t.shape[2] - 1\n",
    "    aux_size = sum(X_t[:,:,n_features][0]!=-0.01)\n",
    "    n_steps_in = X_t.shape[1]\n",
    "    n_steps_out = Out_t.shape[1]\n",
    "    \n",
    "    Llayers = params['Llayers']\n",
    "    Dlayers = params['Dlayers']\n",
    "    drpout = params['drpout']\n",
    "    nodes = params['nodes']\n",
    "    epochs = params['epochs']\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    \n",
    "    seq_input = Input(shape=(n_steps_in, n_features), dtype='float32', name='seq_input')\n",
    "    mask = Masking(mask_value=-0.01)(seq_input)\n",
    "    \n",
    "    if Llayers==1:\n",
    "        lstm_out = LSTM(nodes, activation='relu')(mask)\n",
    "        \n",
    "    else:\n",
    "        lstm_out = LSTM(nodes,activation='relu',return_sequences=True)(mask)\n",
    "        for i in range(Llayers-2):\n",
    "            lstm_out = LSTM(nodes,activation='relu',return_sequences=True)(lstm_out)\n",
    "        lstm_out = LSTM(nodes, activation='relu')(lstm_out)\n",
    "\n",
    "    #output for lstm, corresponds to 0.2 of loss, used to smooth training and regularization:\n",
    "    sec_output = Dense(n_steps_out, activation='sigmoid' ,name='sec_output')(lstm_out)   \n",
    "\n",
    "    auxiliary_input = Input(shape=(aux_size,), name='aux_input')\n",
    "    \n",
    "\n",
    "    mrgLayer = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "    # We stack a deep densely-connected network on top\n",
    "    for i in range(Dlayers):\n",
    "        mrgLayer = Dense(nodes, activation='relu')(mrgLayer)\n",
    "        if drpout>0:\n",
    "            mrgLayer = Dropout(drpout)(mrgLayer)\n",
    "\n",
    "    # And finally we add the main logistic regression layer\n",
    "    main_output = Dense(n_steps_out, activation='sigmoid', name='main_output')(mrgLayer)\n",
    "\n",
    "    modelaux = Model(inputs=[seq_input, auxiliary_input], outputs=[main_output, sec_output])\n",
    "\n",
    "\n",
    "    modelaux.compile(optimizer='adam', loss='mse',\n",
    "              loss_weights=[1., 0.2])\n",
    "    \n",
    "    \n",
    "    aux_t = X_t[:,:,n_features][:,-aux_size:]\n",
    "    aux_val = X_val[:,:,n_features][:,-aux_size:]\n",
    "    \n",
    "    X_t = X_t[:,:,:n_features]\n",
    "    X_val = X_val[:,:,:n_features]\n",
    "    \n",
    "    \n",
    "    Out_t = Out_t[:,:,0] # 0 is index for X\n",
    "    Out_val = Out_val[:,:,0]\n",
    "    \n",
    "    start = time.time()\n",
    "    history = modelaux.fit([X_t,aux_t], [Out_t,Out_t], \n",
    "                        validation_data = [[X_val, aux_val],[Out_val,Out_val]],\n",
    "                        epochs = epochs,\n",
    "                        verbose = 100, \n",
    "                        batch_size = batch_size)\n",
    "    \n",
    "    end = time.time()\n",
    "\n",
    "    print (\"Finished Fitting Model. # of Epochs: %d\\n Time Taken : %d secs\"\n",
    "           % (epochs,end - start))\n",
    "    \n",
    "    return history, modelaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inpTrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-363d9654ef6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m scan_object = ta.Scan(x = inpTrain,\n\u001b[0m\u001b[1;32m      2\u001b[0m                       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAuxLSTM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mval_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inpTrain' is not defined"
     ]
    }
   ],
   "source": [
    "scan_object = ta.Scan(x = inpTrain,\n",
    "                      y = outTrain, \n",
    "                      params = p,\n",
    "                      model = AuxLSTM,\n",
    "                      val_split = 0.2,\n",
    "                      experiment_name='AuxLSTM_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing the results data frame\n",
    "scan_object.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_features = (inpTrain.shape[2]-1)\n",
    "# n_steps_in = inpTrain.shape[1]\n",
    "# n_steps_out = outTrain.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AuxLSTM(BaseEstimator):\n",
    "    \n",
    "#     def __init__(self, nodes=50, batch_size=32,\n",
    "#                  epochs=200, Dlayers=1, Llayers=1, features=6, steps_in=0, steps_out=0, drpout=0.5\n",
    "#                  ):\n",
    "\n",
    "#         self.nodes = nodes\n",
    "#         self.features = features\n",
    "#         self.steps_in = steps_in\n",
    "#         self.steps_out = steps_out\n",
    "#         self.epochs = epochs\n",
    "#         self.batch_size = batch_size\n",
    "#         self.Dlayers= Dlayers   #number of hidden dense layers\n",
    "#         self.Llayers = Llayers  #number of lstm layers\n",
    "#         self.maxXY=654.9\n",
    "#         self.minXY=650.1\n",
    "#         self.drpout=drpout\n",
    "\n",
    "\n",
    "#     def create_model(self):\n",
    "        \n",
    "#         seq_input = Input(shape=(self.steps_in, self.features), dtype='float32', name='seq_input')\n",
    "#         mask = Masking(mask_value=-0.01)(seq_input)\n",
    "#         if self.Llayers==1:\n",
    "            \n",
    "#             lstm_out = LSTM(self.nodes, activation='relu')(mask)\n",
    "            \n",
    "#         else:\n",
    "#             lstm_out = LSTM(self.nodes,activation='relu',return_sequences=True)(mask)\n",
    "            \n",
    "#             for i in range(self.Llayers-2):\n",
    "#                 lstm_out = LSTM(self.nodes,activation='relu',return_sequences=True)(lstm_out)\n",
    "                \n",
    "#             lstm_out = LSTM(self.nodes, activation='relu')(lstm_out)\n",
    "\n",
    "#         #output for lstm, corresponds to 0.2 of loss, used to smooth training and regularization:\n",
    "#         sec_output = Dense(self.steps_out, activation='sigmoid' ,name='sec_output')(lstm_out)   \n",
    "\n",
    "#         auxiliary_input = Input(shape=(14,), name='aux_input')\n",
    "        \n",
    "#         x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "#         # We stack a deep densely-connected network on top\n",
    "#         for i in range(self.Dlayers):\n",
    "#             x = Dense(self.nodes, activation='relu')(x)\n",
    "#             if self.drpout>0:\n",
    "#                 x = Dropout(self.drpout)(x)\n",
    "\n",
    "#         # And finally we add the main logistic regression layer\n",
    "#         main_output = Dense(self.steps_out, activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "#         modelaux = Model(inputs=[seq_input, auxiliary_input], outputs=[main_output, sec_output])\n",
    "\n",
    "\n",
    "#         modelaux.compile(optimizer='adam', loss='mse',\n",
    "#                       loss_weights=[1., 0.2])\n",
    "#         return modelaux\n",
    "    \n",
    "#     def fit(self,inp,out):\n",
    "#         start = time.time()\n",
    "#         X = inp[:,:,:self.features]\n",
    "#         aux = inp[:,:,self.features][:,-14:] \n",
    "#         out = out[:,:,0]\n",
    "#         self.model = self.create_model()\n",
    "#         self.model.fit([X,aux], [out,out], epochs = self.epochs, verbose = 100, batch_size = self.batch_size)\n",
    "#         end = time.time()\n",
    "#         print (\"Finished Fitting AuxModel. # of Epochs: %d\\n Time Taken : %d secs\"\n",
    "#                % (self.epochs,end - start))\n",
    "#         return self\n",
    "    \n",
    "#     def predict(self, inp):\n",
    "#         X = inp[:,:,:self.features]\n",
    "#         aux = inp[:,:,self.features][:,-14:]\n",
    "        \n",
    "#         return self.model.predict([X,aux])\n",
    "    \n",
    "#     def score(self,inp,out):\n",
    "#         out = out[:,:,0]\n",
    "#         outpred = self.predict(inp)[0]        #auxlstm has two identical outputs, 1st in chosen\n",
    "#         outinv = np.zeros(out.shape)\n",
    "#         outpredinv = np.zeros(outpred.shape)\n",
    "#         for i in range(len(out)):\n",
    "#             pos = sum (n>=0 for n in out[i])    #position of the last actual value on y, not padded\n",
    "#             outinv[i][:pos]= out[i][:pos] * (self.maxXY-self.minXY) + self.minXY\n",
    "#             outpredinv[i][:pos] = outpred[i][:pos]* (self.maxXY-self.minXY) + self.minXY\n",
    "            \n",
    "#         rmseScore = -sqrt(mean_squared_error(outpredinv, outinv))    #negative of RMSE\n",
    "#         return rmseScore\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_features = (inpTrain.shape[2]-1)\n",
    "# n_steps_in = inpTrain.shape[1]\n",
    "# n_steps_out = outTrain.shape[1]\n",
    "\n",
    "# Auxmodel=AuxLSTM(epochs=100, features=n_features,\n",
    "#                     steps_in=n_steps_in, steps_out=n_steps_out)\n",
    " \n",
    "\n",
    "# tuned_params = {\"Dlayers\" : [1,2]}#,'drpout': [0,0.5], \"Llayers\" : [2]}\n",
    "#                # 'batch_size' : [64], 'nodes': [100]  }\n",
    "\n",
    "# gsaux = GridSearchCV(Auxmodel, tuned_params,cv = 5, refit= True, n_jobs=-1)\n",
    "\n",
    "# gridaux_result = gsaux.fit(inpTrain,outTrain)\n",
    "\n",
    "# gridaux_result.cv_results_\n",
    "\n",
    "# bestauxLSTM = gridaux_result.best_estimator_\n",
    "\n",
    "# bestauxLSTM.score(inpTest,outTest)\n",
    "\n",
    "# np.save('/home/arash/ProjectVR/models/GridResults/Aux0_5LSTM001.npy',gridaux_result.cv_results_)\n",
    "# bestauxLSTM = gridaux_result.best_estimator_\n",
    "\n",
    "# joblib.dump(bestauxLSTM, '/home/arash/ProjectVR/models/trainedmodels/Aux0_5LSTM6.pkl')\n",
    "# bestauxLSTM.score(inputseqTEST,ytest)\n",
    "\n",
    "# X = inputseqtrain[:,:,:5]\n",
    "# aux = inputseqtrain[:,:,:5][:,:14]    \n",
    "# ypred = Aux1Best.predict(inputseqtrain)[1]        #auxlstm has two identical outputs, 1st in chosen\n",
    "# yinv = np.zeros(ytrain.shape)\n",
    "# ypredinv = np.zeros(ypred.shape)\n",
    "# for i in range(len(ytrain)):\n",
    "#      pos = sum (n>=0 for n in ytrain[i])                #position of the last actual value on y, not padded\n",
    "#      yinv[i][:pos]= ytrain[i][:pos] * (654.7-650.4) + 650.4\n",
    "#      ypredinv[i][:pos] = ypred[i][:pos]* (654.7-650.4) + 650.4\n",
    "# rmseScore = -sqrt(mean_squared_error(ypredinv, yinv))    #negative of RMSE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# aux1=np.load('/home/arash/ProjectVR/models/GridResults/AuxLSTM00L.npy',allow_pickle=True)\n",
    "\n",
    "# np.zeros((1,10))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Aux1Best=AuxLSTM(epochs=1000, features=n_features,\n",
    "#                     steps_in=n_steps_in, steps_out=n_steps_out,Llayers=2,Dlayers=1,drpout=0.5,\n",
    "#                    batch_size=32, nodes=50)\n",
    "\n",
    "# Aux2Best=AuxLSTM(epochs=100, features=n_features,\n",
    "#                     steps_in=n_steps_in, steps_out=n_steps_out,Llayers=2,Dlayers=1,drpout=0.5,\n",
    "#                    batch_size=32, nodes=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestaux=joblib.load('/home/arash/ProjectVR/models/trainedmodels/AuxLSTM2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestvlstm=joblib.load('/home/arash/ProjectVR/models/trainedmodels/VLSTM1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestaux.score(inputseqtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestaux0_5=joblib.load('/home/arash/ProjectVR/models/trainedmodels/Aux0_5LSTM6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxXY=654.9\n",
    "minXY=650.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = bestaux.predict(inputseqtrain)[0][num]        #auxlstm has two identical outputs, 1st in chosen\n",
    "ypredvlstm=bestvlstm.predict(inputseqtrain)[num] \n",
    "\n",
    "\n",
    "pos = sum (n>=0 for n in ytrain[num])                #position of the last actual value on y, not padded\n",
    "\n",
    "title= \"X Coordinate\"\n",
    "y= ypred[:pos]* (maxXY-minXY) + minXY\n",
    "x = np.arange(0,len(y)/10,0.1)\n",
    "xv=x\n",
    "yv=ypredvlstm[:pos]* (maxXY-minXY) + minXY\n",
    "\n",
    "ytrue = ytrain[num][:pos] * (maxXY-minXY) + minXYnj\n",
    "xtrue = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(xold,yold,numsteps):\n",
    "    xnew = []\n",
    "    ynew = []\n",
    "    for i in range(len(xold)-1):\n",
    "        difX = xold[i+1]-xold[i]\n",
    "        stepsX = difX/numsteps\n",
    "        difY = yold[i+1]-yold[i]\n",
    "        stepsY = difY/numsteps\n",
    "        for s in range(numsteps):\n",
    "            xnew = np.append(xnew,xold[i]+s*stepsX)\n",
    "            ynew = np.append(ynew,yold[i]+s*stepsY)\n",
    "    return xnew,ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=augment(x,y,10)\n",
    "xv,yv=augment(xv,yv,10)\n",
    "xtrue,ytrue=augment(xtrue,ytrue,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true0=pd.DataFrame(ytrue,xtrue)\n",
    "pred0=pd.DataFrame(y,x)\n",
    "Vpred0=pd.DataFrame(yv,xv)\n",
    "true0.columns = {title}\n",
    "\n",
    "pred0.columns={title}\n",
    "Vpred0.columns={title}\n",
    "\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/home/arash/anaconda3/envs/gpusupport/bin/ffmpeg'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=20, metadata=dict(artist='Arash'), bitrate=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.xlim(0, len(x)/100)\n",
    "plt.ylim(np.min(pred0)[0], np.max(pred0)[0])\n",
    "plt.xlabel('Time (s)',fontsize=14)\n",
    "plt.ylabel(title,fontsize=14)\n",
    "plt.title('Pedestrian Position Over Time',fontsize=14)\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "custom_lines = [Line2D([0], [0], color='b', lw=4),\n",
    "                Line2D([0], [0], color='g', lw=4),\n",
    "                Line2D([0], [0], color='r', lw=4)]\n",
    "plt.legend(custom_lines, ['AuxLSTM', 'True Trajectory', 'Vanilla LSTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(i):\n",
    "    dataaux = pred0.iloc[:int(i+1)] #select data range\n",
    "    datatrue = true0.iloc[:int(i+1)] #select data range\n",
    "    dataV=Vpred0.iloc[:int(i+1)] #select data range\n",
    "    p = sns.lineplot(x=dataaux.index, y=dataaux[title], data=dataaux,markers=True,color=\"b\")\n",
    "    p2 = sns.lineplot(x=datatrue.index, y=datatrue[title], data=datatrue, markers=True,color=\"g\")\n",
    "    p3 = sns.lineplot(x=dataV.index, y=dataV[title], data=dataV, markers=True,color=\"r\")\n",
    "    sns.set_style(\"white\")\n",
    "    p.tick_params(labelsize=10)\n",
    "    p2.tick_params(labelsize=10)\n",
    "    p3.tick_params(labelsize=10)\n",
    "    plt.setp(p.lines,linewidth=2)\n",
    "    plt.setp(p2.lines,linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = animation.FuncAnimation(fig, animate,frames=400 ,repeat=True)\n",
    "\n",
    "ani.save('Sample03.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
