{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code for lstm network development. data preparation for lstm can be found in preprocess/seqdata.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from math import ceil\n",
    "import time\n",
    "import glob,os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pdb\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, Dense, Input, Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "with open('/home/arash/ProjectVR/cleaneddata/seqdata', 'rb') as f:\n",
    "    allseqdata = pickle.load(f)\n",
    "\n",
    "inputseq=allseqdata[0]\n",
    "ypadded=allseqdata[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "with open('/home/arash/ProjectVR/cleaneddata/auxdata', 'rb') as f:\n",
    "    allauxdata = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3309, 14)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allauxdata.shape     \n",
    "# allauxdata columns' corresponding variables:\n",
    "#'Snowy','Night', 'One way', 'two way', 'Two way with median','Speed Limit_30.0', \n",
    "#'Speed Limit_40.0', 'Speed Limit_50.0','Lane Width_2.5', 'Lane Width_2.75', 'Lane Width_3.0',\n",
    "#'Mean Arrival Rate_530.0', 'Mean Arrival Rate_750.0',\n",
    "#'Mean Arrival Rate_1100.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3309, 102, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputseq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3309, 144)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypadded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####not use scaled measures for now\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "Xscaled = scaler.fit_transform(Xpadded)\n",
    "\n",
    "yscaled = scaler.fit_transform(ypadded)\n",
    "\n",
    "o1scaled = scaler.fit_transform(o1padded)\n",
    "o2scaled = scaler.fit_transform(o2padded)\n",
    "o3scaled = scaler.fit_transform(o3padded)\n",
    "distscaled = scaler.fit_transform(distpadded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 float32\n"
     ]
    }
   ],
   "source": [
    "#check if data is float:\n",
    "print(ypadded.dtype,inputseq.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = inputseq.shape[2]\n",
    "n_steps_in=inputseq.shape[1]\n",
    "n_steps_out=ypadded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate validation data and test set\n",
    "import random\n",
    "tst=0.2                 #% if test data\n",
    "val=0.2                 #% if valid data       \n",
    "tstsize = int(np.floor(len(inputseq) * tst))\n",
    "valsize = int(np.floor(len(inputseq) * val))\n",
    "\n",
    "tstlabel=[]\n",
    "for i in range(tstsize):\n",
    "    temp = random.randint(0,inputseq.shape[0]-1)\n",
    "    tstlabel.append(temp)\n",
    "\n",
    "Xtest=inputseq[tstlabel]\n",
    "ytest=ypadded[tstlabel]\n",
    "auxdatatest = allauxdata[tstlabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnlabel=[i for i in range(inputseq.shape[0]) if i not in tstlabel]\n",
    "trnsize=len(trnlabel)\n",
    "\n",
    "Xtrain = inputseq[trnlabel]          #Excluding test set\n",
    "ytrain = ypadded[trnlabel]\n",
    "auxdatatrain = allauxdata[trnlabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vallabel=[]\n",
    "for i in range(valsize):\n",
    "    temp = trnlabel[random.randint(0,trnsize-1)]\n",
    "    vallabel.append(temp)\n",
    "\n",
    "Xval=inputseq[vallabel]\n",
    "yval=ypadded[vallabel]\n",
    "auxdataval=allauxdata[vallabel]\n",
    "\n",
    "trainlabel=[i for i in range(Xtrain.shape[0]) if i not in [vallabel]]\n",
    "Xtrain=Xtrain[trainlabel]\n",
    "ytrain=ytrain[trainlabel]\n",
    "auxdatatrain = auxdatatrain[trainlabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vanilla lstm model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history=model.fit(Xtrain, ytrain,\n",
    "                  epochs=200, verbose=1,batch_size=32,\n",
    "                  validation_data=(Xval, yval))\n",
    "                  \n",
    "\n",
    "\n",
    "\n",
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "#pyplot.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(Xval)\n",
    "\n",
    "Xtrain[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lstm model with aux variables\n",
    "# sequential input: meant to receive sequence data (inputseq)\n",
    "# Note that we can name any layer by passing it a \"name\" argument.\n",
    "seq_input = Input(shape=(n_steps_in, n_features), dtype='float32', name='seq_input')\n",
    "\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(50,activation='relu')(seq_input)\n",
    "auxiliary_output = Dense(n_steps_out, name='aux_output')(lstm_out)\n",
    "auxiliary_input = Input(shape=(allauxdata.shape[1],), name='aux_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(n_steps_out, name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[seq_input, auxiliary_input], outputs=[main_output, auxiliary_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse',\n",
    "              loss_weights=[1., 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2718 samples, validate on 661 samples\n",
      "Epoch 1/50\n",
      "2718/2718 [==============================] - 3s 1ms/step - loss: 37385.2148 - main_output_loss: 28848.3495 - aux_output_loss: 42684.3238 - val_loss: 26210.6752 - val_main_output_loss: 19657.7969 - val_aux_output_loss: 32764.3922\n",
      "Epoch 2/50\n",
      "2718/2718 [==============================] - 3s 960us/step - loss: 10268873.0786 - main_output_loss: 109475.0592 - aux_output_loss: 50796992.1490 - val_loss: 52249.4373 - val_main_output_loss: 25129.2100 - val_aux_output_loss: 135601.1348\n",
      "Epoch 3/50\n",
      "2718/2718 [==============================] - 3s 972us/step - loss: 40476.5259 - main_output_loss: 26670.8574 - aux_output_loss: 69028.3425 - val_loss: 45536.2753 - val_main_output_loss: 22568.7716 - val_aux_output_loss: 114837.5166\n",
      "Epoch 4/50\n",
      "2718/2718 [==============================] - 3s 968us/step - loss: 56536.8962 - main_output_loss: 27273.4896 - aux_output_loss: 146317.0298 - val_loss: 47430.5464 - val_main_output_loss: 23565.3450 - val_aux_output_loss: 119326.0065\n",
      "Epoch 5/50\n",
      "2718/2718 [==============================] - 3s 962us/step - loss: 36013.7276 - main_output_loss: 23251.3550 - aux_output_loss: 63811.8622 - val_loss: 30973.9144 - val_main_output_loss: 20045.2625 - val_aux_output_loss: 54643.2589\n",
      "Epoch 6/50\n",
      "2718/2718 [==============================] - 3s 974us/step - loss: 33759.0353 - main_output_loss: 22671.5753 - aux_output_loss: 55437.2980 - val_loss: 29868.0342 - val_main_output_loss: 19814.1532 - val_aux_output_loss: 50269.4048\n",
      "Epoch 7/50\n",
      "2718/2718 [==============================] - 3s 975us/step - loss: 32988.2529 - main_output_loss: 22627.5961 - aux_output_loss: 51803.2831 - val_loss: 29135.8814 - val_main_output_loss: 19768.7855 - val_aux_output_loss: 46835.4797\n",
      "Epoch 8/50\n",
      "2718/2718 [==============================] - 3s 974us/step - loss: 32290.7679 - main_output_loss: 22534.7627 - aux_output_loss: 48780.0254 - val_loss: 28443.8513 - val_main_output_loss: 19645.0162 - val_aux_output_loss: 43994.1743\n",
      "Epoch 9/50\n",
      "2718/2718 [==============================] - 3s 974us/step - loss: 31735.2941 - main_output_loss: 22587.7455 - aux_output_loss: 45737.7417 - val_loss: 27901.4941 - val_main_output_loss: 19710.1513 - val_aux_output_loss: 40956.7153\n",
      "Epoch 10/50\n",
      "2718/2718 [==============================] - 3s 971us/step - loss: 31739.1734 - main_output_loss: 22621.0252 - aux_output_loss: 45590.7394 - val_loss: 27463.8861 - val_main_output_loss: 19693.5981 - val_aux_output_loss: 38851.4412\n",
      "Epoch 11/50\n",
      "2718/2718 [==============================] - 3s 971us/step - loss: 49453.3123 - main_output_loss: 27901.2525 - aux_output_loss: 107760.2980 - val_loss: 223886.9311 - val_main_output_loss: 54498.4614 - val_aux_output_loss: 846942.3413\n",
      "Epoch 12/50\n",
      "2718/2718 [==============================] - 3s 977us/step - loss: 62813.1348 - main_output_loss: 26375.1195 - aux_output_loss: 182190.0711 - val_loss: 37123.6968 - val_main_output_loss: 19811.8583 - val_aux_output_loss: 86559.1886\n",
      "Epoch 13/50\n",
      "2718/2718 [==============================] - 3s 978us/step - loss: 34567.0274 - main_output_loss: 22531.2247 - aux_output_loss: 60179.0118 - val_loss: 29516.1127 - val_main_output_loss: 19547.6711 - val_aux_output_loss: 49842.2057\n",
      "Epoch 14/50\n",
      "2718/2718 [==============================] - 3s 979us/step - loss: 31571.1530 - main_output_loss: 22417.7446 - aux_output_loss: 45767.0409 - val_loss: 27577.1854 - val_main_output_loss: 19516.2813 - val_aux_output_loss: 40304.5203\n",
      "Epoch 15/50\n",
      "2718/2718 [==============================] - 3s 972us/step - loss: 30313.3896 - main_output_loss: 22412.1646 - aux_output_loss: 39506.1244 - val_loss: 26632.2662 - val_main_output_loss: 19600.0259 - val_aux_output_loss: 35161.2005\n",
      "Epoch 16/50\n",
      "2718/2718 [==============================] - 3s 977us/step - loss: 29549.1384 - main_output_loss: 22381.9058 - aux_output_loss: 35836.1614 - val_loss: 25884.1526 - val_main_output_loss: 19496.5802 - val_aux_output_loss: 31937.8616\n",
      "Epoch 17/50\n",
      "2718/2718 [==============================] - 3s 974us/step - loss: 29049.4510 - main_output_loss: 22351.8161 - aux_output_loss: 33488.1739 - val_loss: 25407.9165 - val_main_output_loss: 19444.7465 - val_aux_output_loss: 29815.8489\n",
      "Epoch 18/50\n",
      "2718/2718 [==============================] - 3s 981us/step - loss: 28755.6687 - main_output_loss: 22375.5874 - aux_output_loss: 31900.4058 - val_loss: 25125.6347 - val_main_output_loss: 19451.7384 - val_aux_output_loss: 28369.4797\n",
      "Epoch 19/50\n",
      "2718/2718 [==============================] - 3s 977us/step - loss: 28505.6843 - main_output_loss: 22351.9637 - aux_output_loss: 30768.6023 - val_loss: 25096.7561 - val_main_output_loss: 19631.8690 - val_aux_output_loss: 27324.4351\n",
      "Epoch 20/50\n",
      "2718/2718 [==============================] - 3s 977us/step - loss: 28332.6576 - main_output_loss: 22346.5031 - aux_output_loss: 29930.7722 - val_loss: 24799.0262 - val_main_output_loss: 19486.7350 - val_aux_output_loss: 26561.4550\n",
      "Epoch 21/50\n",
      "2718/2718 [==============================] - 3s 979us/step - loss: 28199.1671 - main_output_loss: 22339.4402 - aux_output_loss: 29298.6339 - val_loss: 24668.6360 - val_main_output_loss: 19473.5532 - val_aux_output_loss: 25975.4129\n",
      "Epoch 22/50\n",
      "2718/2718 [==============================] - 3s 971us/step - loss: 28087.4033 - main_output_loss: 22325.5452 - aux_output_loss: 28809.2901 - val_loss: 24542.8136 - val_main_output_loss: 19438.1232 - val_aux_output_loss: 25523.4522\n",
      "Epoch 23/50\n",
      "2718/2718 [==============================] - 3s 980us/step - loss: 27994.2849 - main_output_loss: 22310.9518 - aux_output_loss: 28416.6649 - val_loss: 24509.0436 - val_main_output_loss: 19474.8546 - val_aux_output_loss: 25170.9433\n",
      "Epoch 24/50\n",
      "2718/2718 [==============================] - 3s 984us/step - loss: 27945.2461 - main_output_loss: 22324.2124 - aux_output_loss: 28105.1676 - val_loss: 24465.8923 - val_main_output_loss: 19489.7463 - val_aux_output_loss: 24880.7296\n",
      "Epoch 25/50\n",
      "2718/2718 [==============================] - 3s 978us/step - loss: 27913.2482 - main_output_loss: 22346.5121 - aux_output_loss: 27833.6801 - val_loss: 24366.5350 - val_main_output_loss: 19444.5976 - val_aux_output_loss: 24609.6865\n",
      "Epoch 26/50\n",
      "2718/2718 [==============================] - 3s 975us/step - loss: 27836.3719 - main_output_loss: 22314.3934 - aux_output_loss: 27609.8930 - val_loss: 24377.3554 - val_main_output_loss: 19495.6668 - val_aux_output_loss: 24408.4443\n",
      "Epoch 27/50\n",
      "2718/2718 [==============================] - 3s 976us/step - loss: 27790.3211 - main_output_loss: 22306.3303 - aux_output_loss: 27419.9532 - val_loss: 24288.2457 - val_main_output_loss: 19443.4376 - val_aux_output_loss: 24224.0391\n",
      "Epoch 28/50\n",
      "2718/2718 [==============================] - 3s 994us/step - loss: 27773.7965 - main_output_loss: 22323.7323 - aux_output_loss: 27250.3205 - val_loss: 24331.1129 - val_main_output_loss: 19516.6165 - val_aux_output_loss: 24072.4812\n",
      "Epoch 29/50\n",
      "2718/2718 [==============================] - 3s 997us/step - loss: 27740.5963 - main_output_loss: 22320.8962 - aux_output_loss: 27098.5004 - val_loss: 24294.3737 - val_main_output_loss: 19509.3304 - val_aux_output_loss: 23925.2151\n",
      "Epoch 30/50\n",
      "2718/2718 [==============================] - 3s 995us/step - loss: 27716.1279 - main_output_loss: 22323.4246 - aux_output_loss: 26963.5166 - val_loss: 24202.9885 - val_main_output_loss: 19440.6999 - val_aux_output_loss: 23811.4423\n",
      "Epoch 31/50\n",
      "2718/2718 [==============================] - 3s 1ms/step - loss: 27681.8175 - main_output_loss: 22314.4451 - aux_output_loss: 26836.8612 - val_loss: 24184.5065 - val_main_output_loss: 19448.8056 - val_aux_output_loss: 23678.5038\n",
      "Epoch 32/50\n",
      "2718/2718 [==============================] - 3s 1ms/step - loss: 27649.4092 - main_output_loss: 22304.7068 - aux_output_loss: 26723.5114 - val_loss: 24148.4199 - val_main_output_loss: 19436.0883 - val_aux_output_loss: 23561.6571\n",
      "Epoch 33/50\n",
      "2718/2718 [==============================] - 3s 995us/step - loss: 27627.5829 - main_output_loss: 22305.6474 - aux_output_loss: 26609.6768 - val_loss: 24117.2053 - val_main_output_loss: 19425.2699 - val_aux_output_loss: 23459.6762\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2718/2718 [==============================] - 3s 1ms/step - loss: 27595.2427 - main_output_loss: 22293.4223 - aux_output_loss: 26509.1027 - val_loss: 24102.9829 - val_main_output_loss: 19431.2428 - val_aux_output_loss: 23358.7005\n",
      "Epoch 35/50\n",
      "2718/2718 [==============================] - 3s 992us/step - loss: 27572.9579 - main_output_loss: 22292.0333 - aux_output_loss: 26404.6224 - val_loss: 24072.9785 - val_main_output_loss: 19419.7530 - val_aux_output_loss: 23266.1261\n",
      "Epoch 36/50\n",
      "2718/2718 [==============================] - 3s 1ms/step - loss: 27565.3640 - main_output_loss: 22303.1299 - aux_output_loss: 26311.1699 - val_loss: 24019.1197 - val_main_output_loss: 19385.5069 - val_aux_output_loss: 23168.0623\n",
      "Epoch 37/50\n",
      "2718/2718 [==============================] - 3s 971us/step - loss: 27532.9026 - main_output_loss: 22288.8378 - aux_output_loss: 26220.3235 - val_loss: 24015.0770 - val_main_output_loss: 19398.3383 - val_aux_output_loss: 23083.6930\n",
      "Epoch 38/50\n",
      "2718/2718 [==============================] - 3s 976us/step - loss: 27511.2084 - main_output_loss: 22284.5055 - aux_output_loss: 26133.5141 - val_loss: 24098.6602 - val_main_output_loss: 19500.5438 - val_aux_output_loss: 22990.5812\n",
      "Epoch 39/50\n",
      "2718/2718 [==============================] - 3s 977us/step - loss: 27511.2867 - main_output_loss: 22303.0860 - aux_output_loss: 26041.0034 - val_loss: 24138.5520 - val_main_output_loss: 19555.0313 - val_aux_output_loss: 22917.6026\n",
      "Epoch 40/50\n",
      "2718/2718 [==============================] - 3s 973us/step - loss: 27491.3108 - main_output_loss: 22298.1870 - aux_output_loss: 25965.6183 - val_loss: 24027.4928 - val_main_output_loss: 19459.8063 - val_aux_output_loss: 22838.4323\n",
      "Epoch 41/50\n",
      "2718/2718 [==============================] - 3s 972us/step - loss: 27449.1552 - main_output_loss: 22275.0248 - aux_output_loss: 25870.6515 - val_loss: 23914.7700 - val_main_output_loss: 19366.4461 - val_aux_output_loss: 22741.6189\n",
      "Epoch 42/50\n",
      "2718/2718 [==============================] - 3s 973us/step - loss: 27462.0044 - main_output_loss: 22300.1037 - aux_output_loss: 25809.5025 - val_loss: 23938.5741 - val_main_output_loss: 19405.4998 - val_aux_output_loss: 22665.3716\n",
      "Epoch 43/50\n",
      "2718/2718 [==============================] - 3s 975us/step - loss: 27448.7823 - main_output_loss: 22304.0248 - aux_output_loss: 25723.7873 - val_loss: 23955.1325 - val_main_output_loss: 19434.6912 - val_aux_output_loss: 22602.2060\n",
      "Epoch 44/50\n",
      "2718/2718 [==============================] - 3s 970us/step - loss: 27428.3553 - main_output_loss: 22299.4125 - aux_output_loss: 25644.7137 - val_loss: 23934.9913 - val_main_output_loss: 19430.2095 - val_aux_output_loss: 22523.9083\n",
      "Epoch 45/50\n",
      "2718/2718 [==============================] - 3s 974us/step - loss: 27425.4465 - main_output_loss: 22309.1888 - aux_output_loss: 25581.2884 - val_loss: 23886.0853 - val_main_output_loss: 19397.4075 - val_aux_output_loss: 22443.3893\n",
      "Epoch 46/50\n",
      "2718/2718 [==============================] - 3s 970us/step - loss: 27377.3397 - main_output_loss: 22278.5383 - aux_output_loss: 25494.0067 - val_loss: 24046.5787 - val_main_output_loss: 19573.4870 - val_aux_output_loss: 22365.4586\n",
      "Epoch 47/50\n",
      "2718/2718 [==============================] - 3s 987us/step - loss: 27377.9635 - main_output_loss: 22292.2585 - aux_output_loss: 25428.5237 - val_loss: 23901.9490 - val_main_output_loss: 19438.6498 - val_aux_output_loss: 22316.4965\n",
      "Epoch 48/50\n",
      "2718/2718 [==============================] - 3s 978us/step - loss: 27377.3784 - main_output_loss: 22304.6362 - aux_output_loss: 25363.7099 - val_loss: 23994.0854 - val_main_output_loss: 19548.8457 - val_aux_output_loss: 22226.1976\n",
      "Epoch 49/50\n",
      "2718/2718 [==============================] - 3s 976us/step - loss: 27359.0307 - main_output_loss: 22298.8897 - aux_output_loss: 25300.7047 - val_loss: 23905.5612 - val_main_output_loss: 19470.6313 - val_aux_output_loss: 22174.6479\n",
      "Epoch 50/50\n",
      "2718/2718 [==============================] - 3s 979us/step - loss: 27370.4751 - main_output_loss: 22322.9161 - aux_output_loss: 25237.7940 - val_loss: 23992.3203 - val_main_output_loss: 19569.4902 - val_aux_output_loss: 22114.1505\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([Xtrain, auxdatatrain], [ytrain, ytrain],\n",
    "          epochs=50, batch_size=32,validation_data=([Xval, auxdataval],[yval, yval]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "#pyplot.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 6.6035028e+02,  6.4569128e+02,  6.5514807e+02, ...,\n",
       "          4.3764824e-01,  3.6512964e+00, -9.2511791e-01],\n",
       "        [ 6.6794171e+02,  6.6805518e+02,  6.6219513e+02, ...,\n",
       "          6.0681862e-01,  3.5338926e+00, -7.3950142e-01],\n",
       "        [ 6.7107965e+02,  6.6781366e+02,  6.6488287e+02, ...,\n",
       "          3.0531745e+00,  9.1032572e+00, -2.8419394e+00],\n",
       "        ...,\n",
       "        [ 6.6107269e+02,  6.6232263e+02,  6.5562268e+02, ...,\n",
       "          5.3936523e-01,  2.1913977e+00, -7.4074644e-01],\n",
       "        [ 6.5626349e+02,  6.4347888e+02,  6.5240222e+02, ...,\n",
       "          1.3708059e-01,  2.7549608e+00, -6.3255733e-01],\n",
       "        [ 6.4659467e+02,  6.5045892e+02,  6.4761505e+02, ...,\n",
       "          2.7854853e+00,  5.0426698e+00, -5.9913993e-03]], dtype=float32),\n",
       " array([[653.56024  , 606.751    , 611.7057   , ...,  -9.393611 ,\n",
       "          -2.6657748, -25.84703  ],\n",
       "        [783.44714  , 743.3518   , 732.0124   , ...,   8.581197 ,\n",
       "         -10.054515 ,   2.906241 ],\n",
       "        [643.4705   , 744.9017   , 862.658    , ...,  31.740086 ,\n",
       "         -14.514384 , -11.670305 ],\n",
       "        ...,\n",
       "        [784.0846   , 743.5555   , 733.0324   , ...,   8.670857 ,\n",
       "         -10.252803 ,   2.35459  ],\n",
       "        [646.885    , 603.82166  , 609.61053  , ...,  -9.179515 ,\n",
       "          -2.6539035, -25.171242 ],\n",
       "        [477.97455  , 582.41064  , 648.11194  , ...,   5.7521863,\n",
       "          -1.8391984,  -4.2262435]], dtype=float32)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a prediction\n",
    "model.predict([Xval,auxdataval])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653.56024"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
