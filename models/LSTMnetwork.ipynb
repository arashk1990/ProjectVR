{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code for lstm network development. data preparation for lstm can be found in preprocess/seqdata.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from math import ceil\n",
    "import time\n",
    "import glob,os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pdb\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, Dense, Input, Embedding, Masking\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "with open('/home/arash/ProjectVR/cleaneddata/seqdata', 'rb') as f:\n",
    "    allseqdata = pickle.load(f)\n",
    "\n",
    "X=allseqdata[0]\n",
    "o1=allseqdata[1]\n",
    "o2=allseqdata[2]\n",
    "o3=allseqdata[3]\n",
    "dist=allseqdata[4]\n",
    "y=allseqdata[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "with open('/home/arash/ProjectVR/cleaneddata/auxdata', 'rb') as f:\n",
    "    allauxdata = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3305, 14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allauxdata.shape     \n",
    "# allauxdata columns' corresponding variables:\n",
    "#'Snowy','Night', 'One way', 'two way', 'Two way with median','Speed Limit_30.0', \n",
    "#'Speed Limit_40.0', 'Speed Limit_50.0','Lane Width_2.5', 'Lane Width_2.75', 'Lane Width_3.0',\n",
    "#'Mean Arrival Rate_530.0', 'Mean Arrival Rate_750.0',\n",
    "#'Mean Arrival Rate_1100.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization using min max method: (keras min max not used due to format difference)\n",
    "#o1,o2,o3: are already bw 0 and 1\n",
    "maxTraj=[]\n",
    "minTraj=[]\n",
    "mindist=[]\n",
    "for i in range(len(X)):                              #findimg max and min of each feature\n",
    "    maxTraj.append(max((max(X[i]),max(y[i]))))\n",
    "    minTraj.append(min((min(X[i]),min(y[i]))))\n",
    "    mindist.append(min((min(dist[i]),min(dist[i]))))\n",
    "    \n",
    "    \n",
    "maxXY=max(maxTraj)\n",
    "maxdist=100\n",
    "minXY=min(minTraj)\n",
    "mindist=min(mindist)\n",
    "Xscaled=[]\n",
    "yscaled=[]\n",
    "distscaled=[]\n",
    "for i in range(len(X)):\n",
    "    Xscaled.append((X[i]-minXY)/(maxXY-minXY))\n",
    "    yscaled.append((y[i]-minXY)/(maxXY-minXY))\n",
    "    distscaled.append((np.array(dist[i])-mindist)/(maxdist-mindist))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xscaled=np.array(Xscaled)\n",
    "yscaled=np.array(yscaled)\n",
    "distscaled=np.array(distscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding sequences to have same length by adding 0s:\n",
    "Xscaled = pad_sequences(Xscaled, dtype='float32')       \n",
    "o1 = pad_sequences(o1,dtype='float32')\n",
    "o2 = pad_sequences(o2,dtype='float32')\n",
    "o3 = pad_sequences(o3,dtype='float32')\n",
    "distscaled = pad_sequences(distscaled,dtype='float32')\n",
    "yscaled = pad_sequences(yscaled, padding='post',dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate validation data and test set\n",
    "import random\n",
    "tst=0.2                 #% if test data\n",
    "val=0.2                 #% if valid data       \n",
    "tstsize = int(np.floor(len(X) * tst))\n",
    "valsize = int(np.floor(len(X) * val))\n",
    "\n",
    "tstlabel=[]\n",
    "for i in range(tstsize):\n",
    "    temp = random.randint(0,X.shape[0]-1)\n",
    "    tstlabel.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=Xscaled[tstlabel]\n",
    "o1test=o1[tstlabel]\n",
    "o2test=o2[tstlabel]\n",
    "o3test=o3[tstlabel]\n",
    "disttest=distscaled[tstlabel]\n",
    "ytest=yscaled[tstlabel]\n",
    "\n",
    "auxdatatest = allauxdata[tstlabel]\n",
    "\n",
    "trnlabel=[i for i in range(X.shape[0]) if i not in tstlabel]\n",
    "trnsize=len(trnlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xscaled[trnlabel]          #Excluding test set\n",
    "o1train=o1[trnlabel]\n",
    "o2train=o2[trnlabel]\n",
    "o3train=o3[trnlabel]\n",
    "disttrain=distscaled[trnlabel]\n",
    "ytrain = yscaled[trnlabel]\n",
    "auxdatatrain = allauxdata[trnlabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vallabel=[]\n",
    "for i in range(valsize):\n",
    "    temp = trnlabel[random.randint(0,trnsize-1)]\n",
    "    vallabel.append(temp)\n",
    "\n",
    "Xval=Xscaled[vallabel]\n",
    "o1val=o1[vallabel]\n",
    "o2val=o2[vallabel]\n",
    "o3val=o3[vallabel]\n",
    "distval=distscaled[vallabel]\n",
    "yval=yscaled[vallabel]\n",
    "auxdataval=allauxdata[vallabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabel=[i for i in range(Xtrain.shape[0]) if i not in [vallabel]]\n",
    "Xtrain = Xtrain[trainlabel]          #Excluding test set\n",
    "o1train=o1train[trainlabel]\n",
    "o2train=o2train[trainlabel]\n",
    "o3train=o3train[trainlabel]\n",
    "disttrain=disttrain[trainlabel]\n",
    "ytrain = ytrain[trainlabel]\n",
    "auxdatatrain = auxdatatrain[trainlabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xscaled[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputseqTRN=[]\n",
    "inputseqVAL=[]\n",
    "inputseqTST=[]\n",
    "\n",
    "for i in range(Xtrain.shape[0]):\n",
    "    mrg_input=np.transpose(np.vstack((Xtrain[i],o1train[i],o2train[i],o3train[i],disttrain[i])))\n",
    "    inputseqTRN.append(mrg_input)\n",
    "    \n",
    "for i in range(Xval.shape[0]):\n",
    "    mrg_input=np.transpose(np.vstack((Xval[i],o1val[i],o2val[i],o3val[i],distval[i])))\n",
    "    inputseqVAL.append(mrg_input)\n",
    "    \n",
    "for i in range(Xtest.shape[0]):\n",
    "    mrg_input=np.transpose(np.vstack((Xtest[i],o1test[i],o2test[i],o3test[i],disttest[i])))\n",
    "    inputseqTST.append(mrg_input)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain=np.array(inputseqTRN)\n",
    "Xval=np.array(inputseqVAL)\n",
    "Xtest=np.array(inputseqTST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = Xtrain[0].shape[1]\n",
    "n_steps_in=Xtrain.shape[1]\n",
    "n_steps_out=ytrain.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2702 samples, validate on 660 samples\n",
      "Epoch 1/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0225 - val_loss: 0.0155\n",
      "Epoch 2/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0151 - val_loss: 0.0151\n",
      "Epoch 3/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 4/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 5/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0144 - val_loss: 0.0145\n",
      "Epoch 6/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0142 - val_loss: 0.0148\n",
      "Epoch 7/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 8/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 9/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0138 - val_loss: 0.0136\n",
      "Epoch 10/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0136 - val_loss: 0.0136\n",
      "Epoch 11/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0136 - val_loss: 0.0134\n",
      "Epoch 12/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0135 - val_loss: 0.0136\n",
      "Epoch 13/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0134 - val_loss: 0.0138\n",
      "Epoch 14/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 15/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0136 - val_loss: 0.0135\n",
      "Epoch 16/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 17/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0130 - val_loss: 0.0143\n",
      "Epoch 18/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0132 - val_loss: 0.0130\n",
      "Epoch 19/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 20/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 21/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 22/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0127 - val_loss: 0.0138\n",
      "Epoch 23/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 24/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0125 - val_loss: 0.0127\n",
      "Epoch 25/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 26/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0125 - val_loss: 0.0128\n",
      "Epoch 27/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0123 - val_loss: 0.0127\n",
      "Epoch 28/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0124 - val_loss: 0.0126\n",
      "Epoch 29/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0123 - val_loss: 0.0125\n",
      "Epoch 30/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0122 - val_loss: 0.0131\n",
      "Epoch 31/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0123 - val_loss: 0.0122\n",
      "Epoch 32/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 33/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 34/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0121 - val_loss: 0.0123\n",
      "Epoch 35/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0119 - val_loss: 0.0124\n",
      "Epoch 36/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0117 - val_loss: 0.0123\n",
      "Epoch 37/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 38/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 39/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 40/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 41/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0116 - val_loss: 0.0119\n",
      "Epoch 42/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0114 - val_loss: 0.0119\n",
      "Epoch 43/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 44/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0115 - val_loss: 0.0120\n",
      "Epoch 45/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 46/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 47/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 48/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 49/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 50/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 51/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 52/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 53/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 54/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 55/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 56/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 57/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 58/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 59/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 60/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 61/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 62/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 63/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 64/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 65/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 66/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 67/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 68/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 69/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 70/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 71/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 72/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 73/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 74/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 75/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 76/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 77/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 78/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0094 - val_loss: 0.0091\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 80/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 81/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 82/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 83/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 84/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 85/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 86/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0088 - val_loss: 0.0093\n",
      "Epoch 87/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 88/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 89/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 90/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 91/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0087 - val_loss: 0.0086\n",
      "Epoch 92/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 93/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0087 - val_loss: 0.0087\n",
      "Epoch 94/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 95/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0084 - val_loss: 0.0085\n",
      "Epoch 96/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 97/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 98/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 99/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0085 - val_loss: 0.0086\n",
      "Epoch 100/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 101/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 102/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 103/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 104/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0082 - val_loss: 0.0087\n",
      "Epoch 105/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 106/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 107/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 108/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 109/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 110/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 111/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 112/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 113/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 114/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 115/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 116/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0076 - val_loss: 0.0083\n",
      "Epoch 117/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 118/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 119/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 120/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 121/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 122/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 123/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 124/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 125/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 126/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 127/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 128/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 129/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 130/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 131/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 132/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 133/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 134/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 135/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 136/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 137/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 138/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 139/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 140/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 141/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 142/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 143/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 144/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 145/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 146/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 147/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 148/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 149/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 150/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 151/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 152/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 153/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 154/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 155/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 156/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 158/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 159/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 160/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 161/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 162/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 163/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 164/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 165/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 166/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 167/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 168/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 169/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 170/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 171/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 172/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 173/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 174/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 175/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 176/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 177/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 178/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 179/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 180/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 181/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 182/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 183/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 184/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 185/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 186/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 187/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 188/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 189/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 190/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 191/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 192/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 193/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 194/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 195/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 196/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 197/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 198/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 199/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 200/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n"
     ]
    }
   ],
   "source": [
    "# define vanilla lstm model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0.0, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history=model.fit(Xtrain, ytrain,\n",
    "                  epochs=200, verbose=1,batch_size=32,\n",
    "                  validation_data=(Xval, yval))\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "#pyplot.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse normalization using min max method\n",
    "def norminverse (y,maxXY,minXY):    # function to inverse normalization on predictions\n",
    "    yinv = np.zeros(y.shape)\n",
    "    for i in range(len(y)):\n",
    "        yinv[i]= y[i] * (maxXY-minXY) + minXY\n",
    "    \n",
    "    return yinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.292\n"
     ]
    }
   ],
   "source": [
    "# make a prediction on validation set\n",
    "yhat = model.predict(Xval)\n",
    "yhatinv = norminverse(yhat,maxXY,minXY)\n",
    "yvalinv = norminverse(yval,maxXY,minXY)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(yhatinv, yvalinv))\n",
    "print('Val RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.684\n"
     ]
    }
   ],
   "source": [
    "# make a prediction on test set\n",
    "yhat = model.predict(Xtest)\n",
    "\n",
    "yhatinv = norminverse(yhat,maxXY,minXY)\n",
    "ytestinv = norminverse(ytest,maxXY,minXY)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(yhatinv, ytestinv))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lstm model with aux variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2702 samples, validate on 660 samples\n",
      "Epoch 1/200\n",
      "2702/2702 [==============================] - 7s 3ms/step - loss: 0.0309 - main_output_loss: 0.0260 - aux_output_loss: 0.0245 - val_loss: 0.0203 - val_main_output_loss: 0.0172 - val_aux_output_loss: 0.0158\n",
      "Epoch 2/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0190 - main_output_loss: 0.0159 - aux_output_loss: 0.0153 - val_loss: 0.0189 - val_main_output_loss: 0.0158 - val_aux_output_loss: 0.0152\n",
      "Epoch 3/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0181 - main_output_loss: 0.0151 - aux_output_loss: 0.0149 - val_loss: 0.0180 - val_main_output_loss: 0.0151 - val_aux_output_loss: 0.0149\n",
      "Epoch 4/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0175 - main_output_loss: 0.0146 - aux_output_loss: 0.0148 - val_loss: 0.0178 - val_main_output_loss: 0.0148 - val_aux_output_loss: 0.0148\n",
      "Epoch 5/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0172 - main_output_loss: 0.0143 - aux_output_loss: 0.0145 - val_loss: 0.0173 - val_main_output_loss: 0.0144 - val_aux_output_loss: 0.0145\n",
      "Epoch 6/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0169 - main_output_loss: 0.0140 - aux_output_loss: 0.0142 - val_loss: 0.0169 - val_main_output_loss: 0.0141 - val_aux_output_loss: 0.0143\n",
      "Epoch 7/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0167 - main_output_loss: 0.0139 - aux_output_loss: 0.0141 - val_loss: 0.0168 - val_main_output_loss: 0.0140 - val_aux_output_loss: 0.0141\n",
      "Epoch 8/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0165 - main_output_loss: 0.0137 - aux_output_loss: 0.0140 - val_loss: 0.0168 - val_main_output_loss: 0.0140 - val_aux_output_loss: 0.0142\n",
      "Epoch 9/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0165 - main_output_loss: 0.0137 - aux_output_loss: 0.0139 - val_loss: 0.0164 - val_main_output_loss: 0.0137 - val_aux_output_loss: 0.0139\n",
      "Epoch 10/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0162 - main_output_loss: 0.0134 - aux_output_loss: 0.0137 - val_loss: 0.0163 - val_main_output_loss: 0.0136 - val_aux_output_loss: 0.0139\n",
      "Epoch 11/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0161 - main_output_loss: 0.0133 - aux_output_loss: 0.0136 - val_loss: 0.0162 - val_main_output_loss: 0.0135 - val_aux_output_loss: 0.0138\n",
      "Epoch 12/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0162 - main_output_loss: 0.0134 - aux_output_loss: 0.0137 - val_loss: 0.0161 - val_main_output_loss: 0.0134 - val_aux_output_loss: 0.0139\n",
      "Epoch 13/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0161 - main_output_loss: 0.0133 - aux_output_loss: 0.0136 - val_loss: 0.0166 - val_main_output_loss: 0.0139 - val_aux_output_loss: 0.0137\n",
      "Epoch 14/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0159 - main_output_loss: 0.0132 - aux_output_loss: 0.0135 - val_loss: 0.0157 - val_main_output_loss: 0.0130 - val_aux_output_loss: 0.0135\n",
      "Epoch 15/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0161 - main_output_loss: 0.0133 - aux_output_loss: 0.0136 - val_loss: 0.0163 - val_main_output_loss: 0.0135 - val_aux_output_loss: 0.0139\n",
      "Epoch 16/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0156 - main_output_loss: 0.0130 - aux_output_loss: 0.0134 - val_loss: 0.0156 - val_main_output_loss: 0.0129 - val_aux_output_loss: 0.0132\n",
      "Epoch 17/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0158 - main_output_loss: 0.0131 - aux_output_loss: 0.0134 - val_loss: 0.0156 - val_main_output_loss: 0.0129 - val_aux_output_loss: 0.0134\n",
      "Epoch 18/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0157 - main_output_loss: 0.0130 - aux_output_loss: 0.0134 - val_loss: 0.0157 - val_main_output_loss: 0.0130 - val_aux_output_loss: 0.0133\n",
      "Epoch 19/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0154 - main_output_loss: 0.0128 - aux_output_loss: 0.0132 - val_loss: 0.0150 - val_main_output_loss: 0.0124 - val_aux_output_loss: 0.0130\n",
      "Epoch 20/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0153 - main_output_loss: 0.0127 - aux_output_loss: 0.0132 - val_loss: 0.0150 - val_main_output_loss: 0.0124 - val_aux_output_loss: 0.0130\n",
      "Epoch 21/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0155 - main_output_loss: 0.0128 - aux_output_loss: 0.0133 - val_loss: 0.0150 - val_main_output_loss: 0.0124 - val_aux_output_loss: 0.0131\n",
      "Epoch 22/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0150 - main_output_loss: 0.0124 - aux_output_loss: 0.0130 - val_loss: 0.0153 - val_main_output_loss: 0.0126 - val_aux_output_loss: 0.0132\n",
      "Epoch 23/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0151 - main_output_loss: 0.0125 - aux_output_loss: 0.0130 - val_loss: 0.0145 - val_main_output_loss: 0.0119 - val_aux_output_loss: 0.0128\n",
      "Epoch 24/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0148 - main_output_loss: 0.0123 - aux_output_loss: 0.0129 - val_loss: 0.0145 - val_main_output_loss: 0.0119 - val_aux_output_loss: 0.0128\n",
      "Epoch 25/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0147 - main_output_loss: 0.0122 - aux_output_loss: 0.0128 - val_loss: 0.0148 - val_main_output_loss: 0.0122 - val_aux_output_loss: 0.0129\n",
      "Epoch 26/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0147 - main_output_loss: 0.0121 - aux_output_loss: 0.0128 - val_loss: 0.0145 - val_main_output_loss: 0.0120 - val_aux_output_loss: 0.0128\n",
      "Epoch 27/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0147 - main_output_loss: 0.0121 - aux_output_loss: 0.0128 - val_loss: 0.0148 - val_main_output_loss: 0.0122 - val_aux_output_loss: 0.0130\n",
      "Epoch 28/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0145 - main_output_loss: 0.0120 - aux_output_loss: 0.0127 - val_loss: 0.0140 - val_main_output_loss: 0.0115 - val_aux_output_loss: 0.0126\n",
      "Epoch 29/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0145 - main_output_loss: 0.0120 - aux_output_loss: 0.0127 - val_loss: 0.0139 - val_main_output_loss: 0.0114 - val_aux_output_loss: 0.0125\n",
      "Epoch 30/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0143 - main_output_loss: 0.0118 - aux_output_loss: 0.0125 - val_loss: 0.0144 - val_main_output_loss: 0.0119 - val_aux_output_loss: 0.0127\n",
      "Epoch 31/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0143 - main_output_loss: 0.0118 - aux_output_loss: 0.0126 - val_loss: 0.0137 - val_main_output_loss: 0.0112 - val_aux_output_loss: 0.0123\n",
      "Epoch 32/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0141 - main_output_loss: 0.0116 - aux_output_loss: 0.0124 - val_loss: 0.0134 - val_main_output_loss: 0.0110 - val_aux_output_loss: 0.0121\n",
      "Epoch 33/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0139 - main_output_loss: 0.0115 - aux_output_loss: 0.0123 - val_loss: 0.0138 - val_main_output_loss: 0.0113 - val_aux_output_loss: 0.0124\n",
      "Epoch 34/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0141 - main_output_loss: 0.0116 - aux_output_loss: 0.0124 - val_loss: 0.0133 - val_main_output_loss: 0.0109 - val_aux_output_loss: 0.0120\n",
      "Epoch 35/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0137 - main_output_loss: 0.0113 - aux_output_loss: 0.0122 - val_loss: 0.0138 - val_main_output_loss: 0.0112 - val_aux_output_loss: 0.0125\n",
      "Epoch 36/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0137 - main_output_loss: 0.0112 - aux_output_loss: 0.0122 - val_loss: 0.0132 - val_main_output_loss: 0.0108 - val_aux_output_loss: 0.0120\n",
      "Epoch 37/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0136 - main_output_loss: 0.0111 - aux_output_loss: 0.0121 - val_loss: 0.0128 - val_main_output_loss: 0.0105 - val_aux_output_loss: 0.0119\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0135 - main_output_loss: 0.0111 - aux_output_loss: 0.0121 - val_loss: 0.0129 - val_main_output_loss: 0.0105 - val_aux_output_loss: 0.0121\n",
      "Epoch 39/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0135 - main_output_loss: 0.0111 - aux_output_loss: 0.0121 - val_loss: 0.0131 - val_main_output_loss: 0.0107 - val_aux_output_loss: 0.0120\n",
      "Epoch 40/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0130 - main_output_loss: 0.0107 - aux_output_loss: 0.0118 - val_loss: 0.0123 - val_main_output_loss: 0.0100 - val_aux_output_loss: 0.0116\n",
      "Epoch 41/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0132 - main_output_loss: 0.0109 - aux_output_loss: 0.0119 - val_loss: 0.0127 - val_main_output_loss: 0.0104 - val_aux_output_loss: 0.0118\n",
      "Epoch 42/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0127 - main_output_loss: 0.0104 - aux_output_loss: 0.0117 - val_loss: 0.0126 - val_main_output_loss: 0.0102 - val_aux_output_loss: 0.0117\n",
      "Epoch 43/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0129 - main_output_loss: 0.0105 - aux_output_loss: 0.0117 - val_loss: 0.0121 - val_main_output_loss: 0.0098 - val_aux_output_loss: 0.0115\n",
      "Epoch 44/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0126 - main_output_loss: 0.0103 - aux_output_loss: 0.0115 - val_loss: 0.0126 - val_main_output_loss: 0.0103 - val_aux_output_loss: 0.0118\n",
      "Epoch 45/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0127 - main_output_loss: 0.0103 - aux_output_loss: 0.0116 - val_loss: 0.0125 - val_main_output_loss: 0.0102 - val_aux_output_loss: 0.0116\n",
      "Epoch 46/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0124 - main_output_loss: 0.0101 - aux_output_loss: 0.0115 - val_loss: 0.0114 - val_main_output_loss: 0.0092 - val_aux_output_loss: 0.0113\n",
      "Epoch 47/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0121 - main_output_loss: 0.0099 - aux_output_loss: 0.0113 - val_loss: 0.0115 - val_main_output_loss: 0.0093 - val_aux_output_loss: 0.0111\n",
      "Epoch 48/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0121 - main_output_loss: 0.0098 - aux_output_loss: 0.0112 - val_loss: 0.0118 - val_main_output_loss: 0.0096 - val_aux_output_loss: 0.0112\n",
      "Epoch 49/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0121 - main_output_loss: 0.0099 - aux_output_loss: 0.0113 - val_loss: 0.0114 - val_main_output_loss: 0.0091 - val_aux_output_loss: 0.0112\n",
      "Epoch 50/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0122 - main_output_loss: 0.0099 - aux_output_loss: 0.0114 - val_loss: 0.0112 - val_main_output_loss: 0.0089 - val_aux_output_loss: 0.0111\n",
      "Epoch 51/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0119 - main_output_loss: 0.0097 - aux_output_loss: 0.0112 - val_loss: 0.0107 - val_main_output_loss: 0.0085 - val_aux_output_loss: 0.0108\n",
      "Epoch 52/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0119 - main_output_loss: 0.0097 - aux_output_loss: 0.0112 - val_loss: 0.0111 - val_main_output_loss: 0.0090 - val_aux_output_loss: 0.0107\n",
      "Epoch 53/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0115 - main_output_loss: 0.0093 - aux_output_loss: 0.0110 - val_loss: 0.0108 - val_main_output_loss: 0.0086 - val_aux_output_loss: 0.0109\n",
      "Epoch 54/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0116 - main_output_loss: 0.0094 - aux_output_loss: 0.0111 - val_loss: 0.0107 - val_main_output_loss: 0.0085 - val_aux_output_loss: 0.0108\n",
      "Epoch 55/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0112 - main_output_loss: 0.0090 - aux_output_loss: 0.0109 - val_loss: 0.0105 - val_main_output_loss: 0.0084 - val_aux_output_loss: 0.0108\n",
      "Epoch 56/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0110 - main_output_loss: 0.0089 - aux_output_loss: 0.0107 - val_loss: 0.0099 - val_main_output_loss: 0.0079 - val_aux_output_loss: 0.0103\n",
      "Epoch 57/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0112 - main_output_loss: 0.0090 - aux_output_loss: 0.0109 - val_loss: 0.0106 - val_main_output_loss: 0.0085 - val_aux_output_loss: 0.0108\n",
      "Epoch 58/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0112 - main_output_loss: 0.0091 - aux_output_loss: 0.0109 - val_loss: 0.0101 - val_main_output_loss: 0.0080 - val_aux_output_loss: 0.0106\n",
      "Epoch 59/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0111 - main_output_loss: 0.0089 - aux_output_loss: 0.0108 - val_loss: 0.0107 - val_main_output_loss: 0.0085 - val_aux_output_loss: 0.0107\n",
      "Epoch 60/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0109 - main_output_loss: 0.0088 - aux_output_loss: 0.0107 - val_loss: 0.0106 - val_main_output_loss: 0.0085 - val_aux_output_loss: 0.0109\n",
      "Epoch 61/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0108 - main_output_loss: 0.0086 - aux_output_loss: 0.0107 - val_loss: 0.0100 - val_main_output_loss: 0.0079 - val_aux_output_loss: 0.0104\n",
      "Epoch 62/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0107 - main_output_loss: 0.0086 - aux_output_loss: 0.0107 - val_loss: 0.0096 - val_main_output_loss: 0.0076 - val_aux_output_loss: 0.0104\n",
      "Epoch 63/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0104 - main_output_loss: 0.0083 - aux_output_loss: 0.0106 - val_loss: 0.0099 - val_main_output_loss: 0.0079 - val_aux_output_loss: 0.0104\n",
      "Epoch 64/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0106 - main_output_loss: 0.0085 - aux_output_loss: 0.0107 - val_loss: 0.0091 - val_main_output_loss: 0.0072 - val_aux_output_loss: 0.0098\n",
      "Epoch 65/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0104 - main_output_loss: 0.0083 - aux_output_loss: 0.0105 - val_loss: 0.0097 - val_main_output_loss: 0.0077 - val_aux_output_loss: 0.0102\n",
      "Epoch 66/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0103 - main_output_loss: 0.0082 - aux_output_loss: 0.0104 - val_loss: 0.0093 - val_main_output_loss: 0.0073 - val_aux_output_loss: 0.0102\n",
      "Epoch 67/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0101 - main_output_loss: 0.0080 - aux_output_loss: 0.0104 - val_loss: 0.0092 - val_main_output_loss: 0.0073 - val_aux_output_loss: 0.0099\n",
      "Epoch 68/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0101 - main_output_loss: 0.0080 - aux_output_loss: 0.0103 - val_loss: 0.0093 - val_main_output_loss: 0.0073 - val_aux_output_loss: 0.0099\n",
      "Epoch 69/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0097 - main_output_loss: 0.0077 - aux_output_loss: 0.0102 - val_loss: 0.0092 - val_main_output_loss: 0.0072 - val_aux_output_loss: 0.0100\n",
      "Epoch 70/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0097 - main_output_loss: 0.0076 - aux_output_loss: 0.0101 - val_loss: 0.0086 - val_main_output_loss: 0.0068 - val_aux_output_loss: 0.0093\n",
      "Epoch 71/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0096 - main_output_loss: 0.0076 - aux_output_loss: 0.0101 - val_loss: 0.0092 - val_main_output_loss: 0.0073 - val_aux_output_loss: 0.0097\n",
      "Epoch 72/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0098 - main_output_loss: 0.0078 - aux_output_loss: 0.0103 - val_loss: 0.0091 - val_main_output_loss: 0.0072 - val_aux_output_loss: 0.0096\n",
      "Epoch 73/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0096 - main_output_loss: 0.0076 - aux_output_loss: 0.0101 - val_loss: 0.0086 - val_main_output_loss: 0.0066 - val_aux_output_loss: 0.0098\n",
      "Epoch 74/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0093 - main_output_loss: 0.0073 - aux_output_loss: 0.0098 - val_loss: 0.0094 - val_main_output_loss: 0.0074 - val_aux_output_loss: 0.0100\n",
      "Epoch 75/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0092 - main_output_loss: 0.0073 - aux_output_loss: 0.0099 - val_loss: 0.0082 - val_main_output_loss: 0.0063 - val_aux_output_loss: 0.0092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0091 - main_output_loss: 0.0072 - aux_output_loss: 0.0098 - val_loss: 0.0087 - val_main_output_loss: 0.0068 - val_aux_output_loss: 0.0093\n",
      "Epoch 77/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0093 - main_output_loss: 0.0073 - aux_output_loss: 0.0100 - val_loss: 0.0090 - val_main_output_loss: 0.0071 - val_aux_output_loss: 0.0095\n",
      "Epoch 78/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0091 - main_output_loss: 0.0072 - aux_output_loss: 0.0099 - val_loss: 0.0088 - val_main_output_loss: 0.0070 - val_aux_output_loss: 0.0092\n",
      "Epoch 79/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0089 - main_output_loss: 0.0070 - aux_output_loss: 0.0097 - val_loss: 0.0085 - val_main_output_loss: 0.0066 - val_aux_output_loss: 0.0095\n",
      "Epoch 80/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0091 - main_output_loss: 0.0071 - aux_output_loss: 0.0098 - val_loss: 0.0077 - val_main_output_loss: 0.0059 - val_aux_output_loss: 0.0089\n",
      "Epoch 81/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0088 - main_output_loss: 0.0069 - aux_output_loss: 0.0097 - val_loss: 0.0085 - val_main_output_loss: 0.0066 - val_aux_output_loss: 0.0094\n",
      "Epoch 82/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0090 - main_output_loss: 0.0071 - aux_output_loss: 0.0099 - val_loss: 0.0081 - val_main_output_loss: 0.0062 - val_aux_output_loss: 0.0094\n",
      "Epoch 83/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0088 - main_output_loss: 0.0069 - aux_output_loss: 0.0096 - val_loss: 0.0086 - val_main_output_loss: 0.0067 - val_aux_output_loss: 0.0095\n",
      "Epoch 84/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0090 - main_output_loss: 0.0070 - aux_output_loss: 0.0100 - val_loss: 0.0079 - val_main_output_loss: 0.0061 - val_aux_output_loss: 0.0091\n",
      "Epoch 85/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0084 - main_output_loss: 0.0065 - aux_output_loss: 0.0093 - val_loss: 0.0074 - val_main_output_loss: 0.0056 - val_aux_output_loss: 0.0090\n",
      "Epoch 86/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0087 - main_output_loss: 0.0067 - aux_output_loss: 0.0096 - val_loss: 0.0076 - val_main_output_loss: 0.0058 - val_aux_output_loss: 0.0089\n",
      "Epoch 87/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0084 - main_output_loss: 0.0065 - aux_output_loss: 0.0095 - val_loss: 0.0073 - val_main_output_loss: 0.0056 - val_aux_output_loss: 0.0089\n",
      "Epoch 88/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0084 - main_output_loss: 0.0065 - aux_output_loss: 0.0096 - val_loss: 0.0083 - val_main_output_loss: 0.0063 - val_aux_output_loss: 0.0097\n",
      "Epoch 89/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0089 - main_output_loss: 0.0070 - aux_output_loss: 0.0099 - val_loss: 0.0074 - val_main_output_loss: 0.0056 - val_aux_output_loss: 0.0090\n",
      "Epoch 90/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0080 - main_output_loss: 0.0062 - aux_output_loss: 0.0093 - val_loss: 0.0072 - val_main_output_loss: 0.0054 - val_aux_output_loss: 0.0087\n",
      "Epoch 91/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0080 - main_output_loss: 0.0062 - aux_output_loss: 0.0093 - val_loss: 0.0074 - val_main_output_loss: 0.0057 - val_aux_output_loss: 0.0089\n",
      "Epoch 92/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0079 - main_output_loss: 0.0061 - aux_output_loss: 0.0091 - val_loss: 0.0071 - val_main_output_loss: 0.0054 - val_aux_output_loss: 0.0085\n",
      "Epoch 93/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0078 - main_output_loss: 0.0060 - aux_output_loss: 0.0091 - val_loss: 0.0078 - val_main_output_loss: 0.0059 - val_aux_output_loss: 0.0092\n",
      "Epoch 94/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0081 - main_output_loss: 0.0062 - aux_output_loss: 0.0092 - val_loss: 0.0071 - val_main_output_loss: 0.0054 - val_aux_output_loss: 0.0084\n",
      "Epoch 95/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0077 - main_output_loss: 0.0059 - aux_output_loss: 0.0091 - val_loss: 0.0072 - val_main_output_loss: 0.0055 - val_aux_output_loss: 0.0087\n",
      "Epoch 96/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0076 - main_output_loss: 0.0058 - aux_output_loss: 0.0091 - val_loss: 0.0074 - val_main_output_loss: 0.0055 - val_aux_output_loss: 0.0091\n",
      "Epoch 97/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0076 - main_output_loss: 0.0058 - aux_output_loss: 0.0092 - val_loss: 0.0067 - val_main_output_loss: 0.0050 - val_aux_output_loss: 0.0085\n",
      "Epoch 98/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0078 - main_output_loss: 0.0059 - aux_output_loss: 0.0092 - val_loss: 0.0068 - val_main_output_loss: 0.0051 - val_aux_output_loss: 0.0086\n",
      "Epoch 99/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0074 - main_output_loss: 0.0056 - aux_output_loss: 0.0089 - val_loss: 0.0070 - val_main_output_loss: 0.0052 - val_aux_output_loss: 0.0087\n",
      "Epoch 100/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0076 - main_output_loss: 0.0058 - aux_output_loss: 0.0091 - val_loss: 0.0067 - val_main_output_loss: 0.0050 - val_aux_output_loss: 0.0084\n",
      "Epoch 101/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0073 - main_output_loss: 0.0056 - aux_output_loss: 0.0089 - val_loss: 0.0067 - val_main_output_loss: 0.0050 - val_aux_output_loss: 0.0086\n",
      "Epoch 102/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0072 - main_output_loss: 0.0054 - aux_output_loss: 0.0088 - val_loss: 0.0065 - val_main_output_loss: 0.0049 - val_aux_output_loss: 0.0081\n",
      "Epoch 103/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0070 - main_output_loss: 0.0053 - aux_output_loss: 0.0087 - val_loss: 0.0066 - val_main_output_loss: 0.0050 - val_aux_output_loss: 0.0082\n",
      "Epoch 104/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0072 - main_output_loss: 0.0054 - aux_output_loss: 0.0088 - val_loss: 0.0066 - val_main_output_loss: 0.0049 - val_aux_output_loss: 0.0083\n",
      "Epoch 105/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0074 - main_output_loss: 0.0056 - aux_output_loss: 0.0089 - val_loss: 0.0069 - val_main_output_loss: 0.0052 - val_aux_output_loss: 0.0086\n",
      "Epoch 106/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0070 - main_output_loss: 0.0052 - aux_output_loss: 0.0087 - val_loss: 0.0063 - val_main_output_loss: 0.0047 - val_aux_output_loss: 0.0080\n",
      "Epoch 107/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0076 - main_output_loss: 0.0058 - aux_output_loss: 0.0092 - val_loss: 0.0062 - val_main_output_loss: 0.0046 - val_aux_output_loss: 0.0081\n",
      "Epoch 108/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0068 - main_output_loss: 0.0051 - aux_output_loss: 0.0087 - val_loss: 0.0062 - val_main_output_loss: 0.0046 - val_aux_output_loss: 0.0081\n",
      "Epoch 109/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0065 - main_output_loss: 0.0049 - aux_output_loss: 0.0084 - val_loss: 0.0065 - val_main_output_loss: 0.0048 - val_aux_output_loss: 0.0084\n",
      "Epoch 110/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0066 - main_output_loss: 0.0049 - aux_output_loss: 0.0084 - val_loss: 0.0060 - val_main_output_loss: 0.0044 - val_aux_output_loss: 0.0080\n",
      "Epoch 111/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0066 - main_output_loss: 0.0049 - aux_output_loss: 0.0085 - val_loss: 0.0061 - val_main_output_loss: 0.0045 - val_aux_output_loss: 0.0080\n",
      "Epoch 112/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0066 - main_output_loss: 0.0049 - aux_output_loss: 0.0084 - val_loss: 0.0063 - val_main_output_loss: 0.0047 - val_aux_output_loss: 0.0083\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0066 - main_output_loss: 0.0049 - aux_output_loss: 0.0086 - val_loss: 0.0058 - val_main_output_loss: 0.0042 - val_aux_output_loss: 0.0080\n",
      "Epoch 114/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0065 - main_output_loss: 0.0048 - aux_output_loss: 0.0084 - val_loss: 0.0055 - val_main_output_loss: 0.0040 - val_aux_output_loss: 0.0076\n",
      "Epoch 115/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0064 - main_output_loss: 0.0047 - aux_output_loss: 0.0084 - val_loss: 0.0062 - val_main_output_loss: 0.0047 - val_aux_output_loss: 0.0079\n",
      "Epoch 116/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0064 - main_output_loss: 0.0047 - aux_output_loss: 0.0084 - val_loss: 0.0058 - val_main_output_loss: 0.0042 - val_aux_output_loss: 0.0079\n",
      "Epoch 117/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0065 - main_output_loss: 0.0048 - aux_output_loss: 0.0084 - val_loss: 0.0070 - val_main_output_loss: 0.0052 - val_aux_output_loss: 0.0091\n",
      "Epoch 118/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0066 - main_output_loss: 0.0049 - aux_output_loss: 0.0085 - val_loss: 0.0056 - val_main_output_loss: 0.0040 - val_aux_output_loss: 0.0078\n",
      "Epoch 119/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0064 - main_output_loss: 0.0047 - aux_output_loss: 0.0085 - val_loss: 0.0057 - val_main_output_loss: 0.0041 - val_aux_output_loss: 0.0080\n",
      "Epoch 120/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0065 - main_output_loss: 0.0048 - aux_output_loss: 0.0084 - val_loss: 0.0061 - val_main_output_loss: 0.0044 - val_aux_output_loss: 0.0086\n",
      "Epoch 121/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0065 - main_output_loss: 0.0048 - aux_output_loss: 0.0085 - val_loss: 0.0056 - val_main_output_loss: 0.0040 - val_aux_output_loss: 0.0078\n",
      "Epoch 122/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0061 - main_output_loss: 0.0044 - aux_output_loss: 0.0082 - val_loss: 0.0053 - val_main_output_loss: 0.0038 - val_aux_output_loss: 0.0077\n",
      "Epoch 123/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0071 - main_output_loss: 0.0052 - aux_output_loss: 0.0091 - val_loss: 0.0054 - val_main_output_loss: 0.0038 - val_aux_output_loss: 0.0078\n",
      "Epoch 124/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0064 - main_output_loss: 0.0047 - aux_output_loss: 0.0086 - val_loss: 0.0058 - val_main_output_loss: 0.0042 - val_aux_output_loss: 0.0077\n",
      "Epoch 125/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0061 - main_output_loss: 0.0044 - aux_output_loss: 0.0082 - val_loss: 0.0057 - val_main_output_loss: 0.0041 - val_aux_output_loss: 0.0078\n",
      "Epoch 126/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0062 - main_output_loss: 0.0045 - aux_output_loss: 0.0084 - val_loss: 0.0054 - val_main_output_loss: 0.0038 - val_aux_output_loss: 0.0079\n",
      "Epoch 127/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0065 - main_output_loss: 0.0047 - aux_output_loss: 0.0087 - val_loss: 0.0050 - val_main_output_loss: 0.0035 - val_aux_output_loss: 0.0075\n",
      "Epoch 128/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0058 - main_output_loss: 0.0042 - aux_output_loss: 0.0082 - val_loss: 0.0051 - val_main_output_loss: 0.0036 - val_aux_output_loss: 0.0075\n",
      "Epoch 129/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0058 - main_output_loss: 0.0042 - aux_output_loss: 0.0081 - val_loss: 0.0048 - val_main_output_loss: 0.0033 - val_aux_output_loss: 0.0073\n",
      "Epoch 130/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0056 - main_output_loss: 0.0040 - aux_output_loss: 0.0080 - val_loss: 0.0050 - val_main_output_loss: 0.0035 - val_aux_output_loss: 0.0079\n",
      "Epoch 131/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0055 - main_output_loss: 0.0039 - aux_output_loss: 0.0079 - val_loss: 0.0047 - val_main_output_loss: 0.0033 - val_aux_output_loss: 0.0074\n",
      "Epoch 132/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0057 - main_output_loss: 0.0041 - aux_output_loss: 0.0081 - val_loss: 0.0047 - val_main_output_loss: 0.0032 - val_aux_output_loss: 0.0072\n",
      "Epoch 133/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0057 - main_output_loss: 0.0041 - aux_output_loss: 0.0080 - val_loss: 0.0054 - val_main_output_loss: 0.0038 - val_aux_output_loss: 0.0080\n",
      "Epoch 134/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0057 - main_output_loss: 0.0041 - aux_output_loss: 0.0081 - val_loss: 0.0051 - val_main_output_loss: 0.0036 - val_aux_output_loss: 0.0075\n",
      "Epoch 135/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0057 - main_output_loss: 0.0041 - aux_output_loss: 0.0082 - val_loss: 0.0054 - val_main_output_loss: 0.0039 - val_aux_output_loss: 0.0079\n",
      "Epoch 136/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0055 - main_output_loss: 0.0039 - aux_output_loss: 0.0081 - val_loss: 0.0046 - val_main_output_loss: 0.0032 - val_aux_output_loss: 0.0073\n",
      "Epoch 137/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0055 - main_output_loss: 0.0039 - aux_output_loss: 0.0079 - val_loss: 0.0049 - val_main_output_loss: 0.0034 - val_aux_output_loss: 0.0074\n",
      "Epoch 138/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0054 - main_output_loss: 0.0039 - aux_output_loss: 0.0079 - val_loss: 0.0046 - val_main_output_loss: 0.0032 - val_aux_output_loss: 0.0070\n",
      "Epoch 139/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0053 - main_output_loss: 0.0037 - aux_output_loss: 0.0077 - val_loss: 0.0052 - val_main_output_loss: 0.0037 - val_aux_output_loss: 0.0074\n",
      "Epoch 140/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0055 - main_output_loss: 0.0039 - aux_output_loss: 0.0079 - val_loss: 0.0046 - val_main_output_loss: 0.0032 - val_aux_output_loss: 0.0071\n",
      "Epoch 141/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0054 - main_output_loss: 0.0038 - aux_output_loss: 0.0080 - val_loss: 0.0051 - val_main_output_loss: 0.0035 - val_aux_output_loss: 0.0076\n",
      "Epoch 142/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0052 - main_output_loss: 0.0036 - aux_output_loss: 0.0078 - val_loss: 0.0045 - val_main_output_loss: 0.0031 - val_aux_output_loss: 0.0072\n",
      "Epoch 143/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0053 - main_output_loss: 0.0037 - aux_output_loss: 0.0079 - val_loss: 0.0043 - val_main_output_loss: 0.0030 - val_aux_output_loss: 0.0068\n",
      "Epoch 144/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0052 - main_output_loss: 0.0036 - aux_output_loss: 0.0076 - val_loss: 0.0049 - val_main_output_loss: 0.0034 - val_aux_output_loss: 0.0076\n",
      "Epoch 145/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0057 - main_output_loss: 0.0041 - aux_output_loss: 0.0081 - val_loss: 0.0053 - val_main_output_loss: 0.0037 - val_aux_output_loss: 0.0076\n",
      "Epoch 146/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0056 - main_output_loss: 0.0040 - aux_output_loss: 0.0081 - val_loss: 0.0053 - val_main_output_loss: 0.0037 - val_aux_output_loss: 0.0081\n",
      "Epoch 147/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0057 - main_output_loss: 0.0041 - aux_output_loss: 0.0081 - val_loss: 0.0052 - val_main_output_loss: 0.0037 - val_aux_output_loss: 0.0078\n",
      "Epoch 148/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0057 - main_output_loss: 0.0041 - aux_output_loss: 0.0082 - val_loss: 0.0047 - val_main_output_loss: 0.0033 - val_aux_output_loss: 0.0071\n",
      "Epoch 149/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0051 - main_output_loss: 0.0036 - aux_output_loss: 0.0077 - val_loss: 0.0043 - val_main_output_loss: 0.0029 - val_aux_output_loss: 0.0068\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0051 - main_output_loss: 0.0035 - aux_output_loss: 0.0076 - val_loss: 0.0046 - val_main_output_loss: 0.0031 - val_aux_output_loss: 0.0074\n",
      "Epoch 151/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0050 - main_output_loss: 0.0035 - aux_output_loss: 0.0076 - val_loss: 0.0043 - val_main_output_loss: 0.0029 - val_aux_output_loss: 0.0069\n",
      "Epoch 152/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0049 - main_output_loss: 0.0034 - aux_output_loss: 0.0075 - val_loss: 0.0043 - val_main_output_loss: 0.0029 - val_aux_output_loss: 0.0070\n",
      "Epoch 153/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0050 - main_output_loss: 0.0035 - aux_output_loss: 0.0075 - val_loss: 0.0040 - val_main_output_loss: 0.0026 - val_aux_output_loss: 0.0070\n",
      "Epoch 154/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0048 - main_output_loss: 0.0033 - aux_output_loss: 0.0076 - val_loss: 0.0046 - val_main_output_loss: 0.0031 - val_aux_output_loss: 0.0071\n",
      "Epoch 155/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0049 - main_output_loss: 0.0034 - aux_output_loss: 0.0074 - val_loss: 0.0043 - val_main_output_loss: 0.0029 - val_aux_output_loss: 0.0069\n",
      "Epoch 156/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0049 - main_output_loss: 0.0034 - aux_output_loss: 0.0076 - val_loss: 0.0042 - val_main_output_loss: 0.0028 - val_aux_output_loss: 0.0068\n",
      "Epoch 157/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0049 - main_output_loss: 0.0034 - aux_output_loss: 0.0075 - val_loss: 0.0045 - val_main_output_loss: 0.0031 - val_aux_output_loss: 0.0069\n",
      "Epoch 158/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0049 - main_output_loss: 0.0034 - aux_output_loss: 0.0076 - val_loss: 0.0040 - val_main_output_loss: 0.0027 - val_aux_output_loss: 0.0064\n",
      "Epoch 159/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0050 - main_output_loss: 0.0035 - aux_output_loss: 0.0077 - val_loss: 0.0041 - val_main_output_loss: 0.0028 - val_aux_output_loss: 0.0068\n",
      "Epoch 160/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0048 - main_output_loss: 0.0033 - aux_output_loss: 0.0075 - val_loss: 0.0048 - val_main_output_loss: 0.0033 - val_aux_output_loss: 0.0074\n",
      "Epoch 161/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0051 - main_output_loss: 0.0035 - aux_output_loss: 0.0078 - val_loss: 0.0038 - val_main_output_loss: 0.0025 - val_aux_output_loss: 0.0065\n",
      "Epoch 162/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0047 - main_output_loss: 0.0032 - aux_output_loss: 0.0075 - val_loss: 0.0040 - val_main_output_loss: 0.0027 - val_aux_output_loss: 0.0065\n",
      "Epoch 163/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0049 - main_output_loss: 0.0034 - aux_output_loss: 0.0075 - val_loss: 0.0061 - val_main_output_loss: 0.0045 - val_aux_output_loss: 0.0079\n",
      "Epoch 164/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0053 - main_output_loss: 0.0037 - aux_output_loss: 0.0078 - val_loss: 0.0043 - val_main_output_loss: 0.0029 - val_aux_output_loss: 0.0070\n",
      "Epoch 165/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0048 - main_output_loss: 0.0033 - aux_output_loss: 0.0075 - val_loss: 0.0049 - val_main_output_loss: 0.0035 - val_aux_output_loss: 0.0072\n",
      "Epoch 166/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0046 - main_output_loss: 0.0031 - aux_output_loss: 0.0074 - val_loss: 0.0042 - val_main_output_loss: 0.0027 - val_aux_output_loss: 0.0072\n",
      "Epoch 167/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0045 - main_output_loss: 0.0031 - aux_output_loss: 0.0073 - val_loss: 0.0041 - val_main_output_loss: 0.0028 - val_aux_output_loss: 0.0066\n",
      "Epoch 168/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0046 - main_output_loss: 0.0031 - aux_output_loss: 0.0074 - val_loss: 0.0039 - val_main_output_loss: 0.0025 - val_aux_output_loss: 0.0067\n",
      "Epoch 169/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0047 - main_output_loss: 0.0032 - aux_output_loss: 0.0073 - val_loss: 0.0056 - val_main_output_loss: 0.0041 - val_aux_output_loss: 0.0079\n",
      "Epoch 170/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0055 - main_output_loss: 0.0039 - aux_output_loss: 0.0079 - val_loss: 0.0044 - val_main_output_loss: 0.0030 - val_aux_output_loss: 0.0069\n",
      "Epoch 171/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0049 - main_output_loss: 0.0033 - aux_output_loss: 0.0075 - val_loss: 0.0038 - val_main_output_loss: 0.0025 - val_aux_output_loss: 0.0065\n",
      "Epoch 172/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0044 - main_output_loss: 0.0029 - aux_output_loss: 0.0073 - val_loss: 0.0035 - val_main_output_loss: 0.0023 - val_aux_output_loss: 0.0063\n",
      "Epoch 173/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0043 - main_output_loss: 0.0029 - aux_output_loss: 0.0072 - val_loss: 0.0039 - val_main_output_loss: 0.0026 - val_aux_output_loss: 0.0065\n",
      "Epoch 174/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0043 - main_output_loss: 0.0028 - aux_output_loss: 0.0071 - val_loss: 0.0036 - val_main_output_loss: 0.0023 - val_aux_output_loss: 0.0063\n",
      "Epoch 175/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0042 - main_output_loss: 0.0028 - aux_output_loss: 0.0071 - val_loss: 0.0033 - val_main_output_loss: 0.0021 - val_aux_output_loss: 0.0061\n",
      "Epoch 176/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0043 - main_output_loss: 0.0029 - aux_output_loss: 0.0071 - val_loss: 0.0036 - val_main_output_loss: 0.0024 - val_aux_output_loss: 0.0062\n",
      "Epoch 177/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0044 - main_output_loss: 0.0030 - aux_output_loss: 0.0071 - val_loss: 0.0039 - val_main_output_loss: 0.0026 - val_aux_output_loss: 0.0065\n",
      "Epoch 178/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0053 - main_output_loss: 0.0037 - aux_output_loss: 0.0081 - val_loss: 0.0042 - val_main_output_loss: 0.0028 - val_aux_output_loss: 0.0068\n",
      "Epoch 179/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0046 - main_output_loss: 0.0031 - aux_output_loss: 0.0074 - val_loss: 0.0040 - val_main_output_loss: 0.0027 - val_aux_output_loss: 0.0065\n",
      "Epoch 180/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0045 - main_output_loss: 0.0030 - aux_output_loss: 0.0074 - val_loss: 0.0042 - val_main_output_loss: 0.0028 - val_aux_output_loss: 0.0069\n",
      "Epoch 181/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0045 - main_output_loss: 0.0030 - aux_output_loss: 0.0073 - val_loss: 0.0039 - val_main_output_loss: 0.0026 - val_aux_output_loss: 0.0064\n",
      "Epoch 182/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0042 - main_output_loss: 0.0028 - aux_output_loss: 0.0071 - val_loss: 0.0036 - val_main_output_loss: 0.0023 - val_aux_output_loss: 0.0064\n",
      "Epoch 183/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0041 - main_output_loss: 0.0027 - aux_output_loss: 0.0070 - val_loss: 0.0033 - val_main_output_loss: 0.0021 - val_aux_output_loss: 0.0059\n",
      "Epoch 184/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0039 - main_output_loss: 0.0026 - aux_output_loss: 0.0069 - val_loss: 0.0034 - val_main_output_loss: 0.0021 - val_aux_output_loss: 0.0062\n",
      "Epoch 185/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0041 - main_output_loss: 0.0027 - aux_output_loss: 0.0070 - val_loss: 0.0034 - val_main_output_loss: 0.0022 - val_aux_output_loss: 0.0063\n",
      "Epoch 186/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0041 - main_output_loss: 0.0027 - aux_output_loss: 0.0069 - val_loss: 0.0036 - val_main_output_loss: 0.0023 - val_aux_output_loss: 0.0064\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0040 - main_output_loss: 0.0026 - aux_output_loss: 0.0069 - val_loss: 0.0033 - val_main_output_loss: 0.0021 - val_aux_output_loss: 0.0061\n",
      "Epoch 188/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0041 - main_output_loss: 0.0027 - aux_output_loss: 0.0070 - val_loss: 0.0033 - val_main_output_loss: 0.0021 - val_aux_output_loss: 0.0060\n",
      "Epoch 189/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0039 - main_output_loss: 0.0025 - aux_output_loss: 0.0068 - val_loss: 0.0034 - val_main_output_loss: 0.0021 - val_aux_output_loss: 0.0062\n",
      "Epoch 190/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0039 - main_output_loss: 0.0025 - aux_output_loss: 0.0068 - val_loss: 0.0032 - val_main_output_loss: 0.0020 - val_aux_output_loss: 0.0062\n",
      "Epoch 191/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0039 - main_output_loss: 0.0026 - aux_output_loss: 0.0068 - val_loss: 0.0033 - val_main_output_loss: 0.0021 - val_aux_output_loss: 0.0060\n",
      "Epoch 192/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0040 - main_output_loss: 0.0026 - aux_output_loss: 0.0069 - val_loss: 0.0035 - val_main_output_loss: 0.0022 - val_aux_output_loss: 0.0063\n",
      "Epoch 193/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0039 - main_output_loss: 0.0025 - aux_output_loss: 0.0068 - val_loss: 0.0032 - val_main_output_loss: 0.0020 - val_aux_output_loss: 0.0059\n",
      "Epoch 194/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0039 - main_output_loss: 0.0026 - aux_output_loss: 0.0068 - val_loss: 0.0037 - val_main_output_loss: 0.0024 - val_aux_output_loss: 0.0065\n",
      "Epoch 195/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0045 - main_output_loss: 0.0031 - aux_output_loss: 0.0072 - val_loss: 0.0036 - val_main_output_loss: 0.0023 - val_aux_output_loss: 0.0063\n",
      "Epoch 196/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0044 - main_output_loss: 0.0030 - aux_output_loss: 0.0071 - val_loss: 0.0042 - val_main_output_loss: 0.0029 - val_aux_output_loss: 0.0066\n",
      "Epoch 197/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0061 - main_output_loss: 0.0044 - aux_output_loss: 0.0083 - val_loss: 0.0046 - val_main_output_loss: 0.0032 - val_aux_output_loss: 0.0070\n",
      "Epoch 198/200\n",
      "2702/2702 [==============================] - 6s 2ms/step - loss: 0.0045 - main_output_loss: 0.0030 - aux_output_loss: 0.0070 - val_loss: 0.0035 - val_main_output_loss: 0.0023 - val_aux_output_loss: 0.0062\n",
      "Epoch 199/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0039 - main_output_loss: 0.0025 - aux_output_loss: 0.0069 - val_loss: 0.0032 - val_main_output_loss: 0.0020 - val_aux_output_loss: 0.0061\n",
      "Epoch 200/200\n",
      "2702/2702 [==============================] - 5s 2ms/step - loss: 0.0037 - main_output_loss: 0.0024 - aux_output_loss: 0.0066 - val_loss: 0.0030 - val_main_output_loss: 0.0018 - val_aux_output_loss: 0.0059\n"
     ]
    }
   ],
   "source": [
    "# sequential input: meant to receive sequence data (inputseq)\n",
    "\n",
    "seq_input = Input(shape=(n_steps_in, n_features), dtype='float32', name='seq_input')\n",
    "mask=Masking(mask_value=0.0)(seq_input)\n",
    "lstm_out = LSTM(50,activation='relu',return_sequences=True)(mask)\n",
    "lstm_out=LSTM(50, activation='relu')(lstm_out)\n",
    "\n",
    "#output for lstm, corresponds to 0.2 of loss, used to smooth training and regularization:\n",
    "auxiliary_output = Dense(n_steps_out, name='aux_output')(lstm_out)   \n",
    "\n",
    "auxiliary_input = Input(shape=(allauxdata.shape[1],), name='aux_input')\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(n_steps_out, name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[seq_input, auxiliary_input], outputs=[main_output, auxiliary_output])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse',\n",
    "              loss_weights=[1., 0.2])\n",
    "\n",
    "history=model.fit([Xtrain, auxdatatrain], [ytrain, ytrain],\n",
    "          epochs=200, batch_size=32,validation_data=([Xval, auxdataval],[yval, yval]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "#pyplot.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val RMSE: 0.197\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat=model.predict([Xval,auxdataval])\n",
    "yhatinv = norminverse(yhat[0],maxXY,minXY)\n",
    "yvalinv = norminverse(yval,maxXY,minXY)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(yhatinv, yvalinv))\n",
    "print('Val RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.616\n"
     ]
    }
   ],
   "source": [
    "# make a prediction on test set\n",
    "yhat=model.predict([Xtest,auxdatatest])\n",
    "yhatinv = norminverse(yhat[0],maxXY,minXY)\n",
    "ytestinv = norminverse(ytest,maxXY,minXY)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(yhatinv, ytestinv))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing model performac for RMSE of the validation set, \n",
    "### all models are trained on same training and validation set, over 200 epochs,\n",
    "###### (Dense mentioned in models are hidden layers, output dense layer not counted\n",
    "* **Vanilla 1**: Batch size=32, LSTM units=50,No Masking input, no sample weights for output, two LSTM layer, loss=mse, **RMSE=~71** \n",
    "\n",
    "* **Vanilla 2:** Batch size=32, LSTM units=50, Masking input, no sample weights for output, two LSTM layer, loss=mse, **VAL RMSE=~0.29, Test RMSE=0.684**\n",
    "\n",
    "* **AuxLSTM 1:** Batch size=32, LSTM units=50, Masking input, no sample weights for output, two LSTM layers, , one hidden dense, loss=mse, **VAL RMSE=~0.197, Test RMSE=0.616**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
