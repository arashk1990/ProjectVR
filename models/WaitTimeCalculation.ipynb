{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "\n",
    "sys.path.append('/home/arash/ProjectVR/')\n",
    "\n",
    "import importlib\n",
    "import deepsurv\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import theano.tensor\n",
    "import lasagne\n",
    "import optunity\n",
    "\n",
    "#import logging\n",
    "#from logging import handlers\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "importlib.reload(deepsurv)\n",
    "\n",
    "from deepsurv import deep_surv, utils\n",
    "\n",
    "#from deepsurv.deepsurv_logger import DeepSurvLogger, TensorboardLogger\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained network and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading json model: {\"n_in\": 19, \"learning_rate\": 0.0008208386784744157, \"hidden_layers_sizes\": [90, 90], \"lr_decay\": 0.000551240234375, \"activation\": \"rectify\", \"dropout\": 0.0, \"batch_norm\": true, \"standardize\": false}\n"
     ]
    }
   ],
   "source": [
    "#deepsurv formatted data    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/xtest', 'rb') as f:\n",
    "    xtest=pickle.load(f)\n",
    "\n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/xtrain', 'rb') as f:\n",
    "    xtrain=pickle.load(f)\n",
    "    \n",
    "#dataframe data with wait times and col names    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/nctest', 'rb') as f:   \n",
    "    NCtest=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/nctrain', 'rb') as f:   \n",
    "    NCtrain=pickle.load(f) \n",
    "    \n",
    "network=deep_surv.load_model_from_json(model_fp = '/home/arash/ProjectVR/models/Deepwait100epochsTuned',\n",
    "                     weights_fp = '/home/arash/ProjectVR/models/deepwait_weights_100_epochs.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting event times\n",
    "To predict the time of event for instances, having an estimation of partial hazard is not sufficient. First, baseline hazard is required to estimate hazard function, which will be a function of time and covariates. The next step would be to calculate survival function. Finally, expected wait time can be calculated by:\n",
    "\\begin{equation}\n",
    "    E(t)=\\int_{t=0}^\\infty S(t)dt\n",
    "\\end{equation}\n",
    "### Baseline Hazard\n",
    "Baseline hazard is interpreted as hazard function regardless of the values of the covariates (or when they are all 0). Different methods have been suggested in the literature for an estimation of baseline hazard. For CPH, the method used in python package is extracted from Breslow [1972]. In their method, \"the underlying survival distribution is\n",
    "parameterized as a continuous one, having constant hazards $\\lambda_i$ between each\n",
    "pair $t_{i-1}$ to $t_i$ of distinct relapse times. If all withdrawals, or censored observations, which\n",
    "occur in the interval $(t_i, t_{i+1})$ are adjusted to have occurred at $t_i$ , the ML estimator of\n",
    "$\\lambda$ in terms of $\\beta$ coefficients at time $t_i$ by:\n",
    "\\begin{equation}\n",
    "\\label{eq:9}\n",
    "    \\lambda_i=\\frac{m_i}{(t_i-t_{i-1})*\\displaystyle \\sum_{j: T_j>T_i } e^{\\beta*Z_j}}\n",
    "\\end{equation}\n",
    "in which $m_i$ is the number of events at time $t_i$, Equation above is provided for CPH. In deepwait, we replace the partial hazards part with the exp of the output of our network \n",
    "\n",
    "deepwait predicts wait time for autonmous vehicle, so the data used will be solely those ones that the car can observe, not sociodemographic etc, and the baseline hazards are calculated based on training data, as the car will not know about other pedestrians at risk etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    }
   ],
   "source": [
    "hazards = network.hazard(xtrain[:,0:network.hyperparams['n_in']])               #calculate partial hazard \n",
    "\n",
    "NCtrain['Partial Hazards'] = hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventtimes = NCtrain.sort_values(by=['Wait Time (s)'])['Wait Time (s)'].unique() #sorted event times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventnum = NCtrain['Wait Time (s)'].value_counts().sort_index() \n",
    "#m_i in the baseline hazard formula, sorted by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "basehazard=[]                      #Baseline hazard according to Breslow Formulation\n",
    "for i in range(len(eventtimes)):\n",
    "    basehazard.append(\n",
    "        list(eventnum)[i] / sum(NCtrain['Partial Hazards'][NCtrain['Wait Time (s)'] >= eventtimes[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00022284056800902033"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basehazard[100]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
