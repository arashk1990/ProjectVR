{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "\n",
    "#sys.path.append('/home/arash/VRdataCleaning/DeepSurv/')\n",
    "\n",
    "import importlib\n",
    "import deepsurv\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "import argparse\n",
    "import uuid\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lasagne\n",
    "import optunity\n",
    "\n",
    "import logging\n",
    "from logging import handlers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "importlib.reload(deepsurv)\n",
    "\n",
    "from deepsurv import deep_surv, utils\n",
    "\n",
    "from deepsurv.deepsurv_logger import DeepSurvLogger, TensorboardLogger\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "import shap  # package used to calculate Shap values\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data: \n",
    "#### xtrain: 80% of all data, devided into xtrainsub & xvalsub (80 and 20%) \n",
    "#### xtest: 20% of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/xtrain', 'rb') as f:\n",
    "    xtrain=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/ytrain', 'rb') as f:\n",
    "    ytrain=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/xtest', 'rb') as f:\n",
    "    xtest=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/ytest', 'rb') as f:\n",
    "    ytest=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/xtrainsub', 'rb') as f:\n",
    "    xtrainsub=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/ytrainsub', 'rb') as f:\n",
    "    ytrainsub=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/xvalsub', 'rb') as f:\n",
    "    xvalsub=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/yvalsub', 'rb') as f:\n",
    "    yvalsub=pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/nctrain', 'rb') as f:\n",
    "    NCtrain=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/nctest', 'rb') as f:\n",
    "    NCtest=pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/nctrain', 'rb') as f:\n",
    "    NCtrain=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/nctest', 'rb') as f:\n",
    "    NCtest=pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logger(logdir):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    format = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "    \n",
    "    # Print to Stdout\n",
    "    ch = logging.StreamHandler(sys.stdout)\n",
    "    ch.setFormatter(format)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "    # Print to Log file\n",
    "    fh = logging.FileHandler(os.path.join(logdir, 'log_' + str(uuid.uuid4())))\n",
    "    fh.setFormatter(format)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "    return logger\n",
    "\n",
    "def format_to_deepsurv(x, y):\n",
    "    return {\n",
    "        'x': x,\n",
    "        'e': y[:,0].astype(np.int32),\n",
    "        't': y[:,1].astype(np.float32)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_box_constraints(file):\n",
    "    with open(file, 'rb') as fp:\n",
    "        return json.loads(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_call_log(file, call_log):\n",
    "    with open(file, 'wb') as fp:\n",
    "        pickle.dump(call_log, fp)\n",
    "\n",
    "def get_objective_function(num_epochs, logdir, update_fn = lasagne.updates.sgd):\n",
    "    '''\n",
    "    Returns the function for Optunity to optimize. The function returned by get_objective_function\n",
    "    takes the parameters: x_train, y_train, x_test, and y_test, and any additional kwargs to \n",
    "    use as hyper-parameters.\n",
    "\n",
    "    The objective function runs a DeepSurv model on the training data and evaluates it against the\n",
    "    a validation set. The result of the function call is the validation concordance index \n",
    "    (which Optunity tries to optimize)\n",
    "    '''\n",
    "    def format_to_deepsurv(x, y):\n",
    "        return {\n",
    "            'x': x,\n",
    "            'e': y[:,0].astype(np.int32),\n",
    "            't': y[:,1].astype(np.float32)\n",
    "        }\n",
    "\n",
    "    def get_hyperparams(x,params):\n",
    "        hyperparams = {\n",
    "            'batch_norm': False,\n",
    "            'activation': 'rectify',\n",
    "            'standardize': True\n",
    "        }\n",
    "\n",
    "        if 'num_layers' in params and 'num_nodes' in params:\n",
    "            params['hidden_layers_sizes'] = [int(params['num_nodes'])] * int(params['num_layers'])\n",
    "            del params['num_layers']\n",
    "            del params['num_nodes']\n",
    "\n",
    "        if 'learning_rate' in params:\n",
    "            params['learning_rate'] = 10 ** params['learning_rate']\n",
    "        \n",
    "        if 'n_in' in params:\n",
    "            params['n_in']= int(np.floor(params['n_in']))\n",
    "        \n",
    "            \n",
    "            \n",
    "\n",
    "        hyperparams.update(params)\n",
    "        return hyperparams\n",
    "\n",
    "    def train_deepsurv(x_train,y_train,x_test,y_test,\n",
    "        **kwargs):\n",
    "        hyperparams = get_hyperparams(x_train,kwargs)\n",
    "        x_train=x_train[:,0:hyperparams['n_in']]\n",
    "        x_test=x_test[:,0:hyperparams['n_in']]\n",
    "     \n",
    "        \n",
    "        # Standardize the datasets\n",
    "        train_mean = x_train.mean(axis = 0)\n",
    "        train_std = x_train.std(axis = 0)\n",
    "\n",
    "        x_train = (x_train - train_mean) / train_std\n",
    "        x_test = (x_test - train_mean) / train_std\n",
    "\n",
    "        train_data = format_to_deepsurv(x_train, y_train)\n",
    "        valid_data = format_to_deepsurv(x_test, y_test)\n",
    "\n",
    "        \n",
    "\n",
    "        # Set up Tensorboard loggers\n",
    "        model_id = str(hash(str(hyperparams)))\n",
    "        run_id = model_id + '_' + str(uuid.uuid4())\n",
    "        logger = TensorboardLogger('hyperparam_search', \n",
    "            os.path.join(logdir,\"tensor_logs\", model_id, run_id))\n",
    "\n",
    "        network = deep_surv.DeepSurv(**hyperparams)\n",
    "        metrics = network.train(train_data, n_epochs = num_epochs, logger=logger, \n",
    "            update_fn = update_fn, verbose = False)\n",
    "\n",
    "        result = network.get_concordance_index(**valid_data)\n",
    "        main_logger.info('Run id: %s | %s | C-Index: %f | Train Loss %f' % (run_id, str(hyperparams), result, metrics['loss'][-1][1]))\n",
    "        return result\n",
    "\n",
    "    return train_deepsurv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Find the optimal hyper-parameters using training data and save them in opt_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "NUM_FOLDS = 8\n",
    "logdir='/home/arash/ProjectVR/logs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'batch_norm': False,\n",
    "    'activation': 'rectify',\n",
    "    'standardize': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'learning_rate' in hyperparams:\n",
    "    hyperparams['learning_rate'] = 10 ** hyperparams['learning_rate']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_logger = load_logger(logdir)\n",
    "\n",
    "\n",
    "#    main_logger.debug('Loading dataset: ' + args.dataset)\n",
    "box_constraints = load_box_constraints('/home/arash/ProjectVR/box_constraints.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'n_in'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-4c837b00a194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m opt_params, call_log, _ = optunity.maximize(opt_fxn, num_evals=40,\n\u001b[1;32m      8\u001b[0m         \u001b[0msolver_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sobol'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         **box_constraints)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py3.6/lib/python3.6/site-packages/optunity/api.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(f, num_evals, solver_name, pmap, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msuggestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     solution, details = optimize(solver, f, maximize=True, max_evals=num_evals,\n\u001b[0;32m--> 181\u001b[0;31m                                  pmap=pmap)\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuggestion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.6/lib/python3.6/site-packages/optunity/api.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(solver, func, maximize, max_evals, pmap, decoder)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0msolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaximumEvaluationsException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# early stopping because maximum number of evaluations is reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.6/lib/python3.6/site-packages/optunity/solvers/Sobol.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, f, maximize, pmap)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mcomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mbest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mbest_pars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#op.itemgetter(best_idx)(scaled)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_pars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.6/lib/python3.6/site-packages/optunity/solvers/Sobol.py\u001b[0m in \u001b[0;36mfwrap\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaximize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.6/lib/python3.6/site-packages/optunity/functions.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.6/lib/python3.6/site-packages/optunity/functions.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_evals\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.6/lib/python3.6/site-packages/optunity/constraints.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConstraintViolation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.6/lib/python3.6/site-packages/optunity/constraints.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mviolations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mConstraintViolation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviolations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.6/lib/python3.6/site-packages/optunity/constraints.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.6/lib/python3.6/site-packages/optunity/cross_validation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_test'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-ae288b174f02>\u001b[0m in \u001b[0;36mtrain_deepsurv\u001b[0;34m(x_train, y_train, x_test, y_test, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         **kwargs):\n\u001b[1;32m     48\u001b[0m         \u001b[0mhyperparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hyperparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_in'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mx_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_in'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'n_in'"
     ]
    }
   ],
   "source": [
    "opt_fxn = get_objective_function(NUM_EPOCHS, logdir, \n",
    "                                 utils.get_optimizer_from_str('adam'))\n",
    "\n",
    "opt_fxn = optunity.cross_validated(x=xtrain, y=ytrain, num_folds=NUM_FOLDS)(opt_fxn)\n",
    "\n",
    "\n",
    "opt_params, call_log, _ = optunity.maximize(opt_fxn, num_evals=40,\n",
    "        solver_name='sobol',\n",
    "        **box_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr_decay': 0.00055607421875,\n",
       " 'learning_rate': -3.290703125,\n",
       " 'num_nodes': 50.3013671875,\n",
       " 'num_layers': 3.02787109375,\n",
       " 'momentum': 0.8054541015624999,\n",
       " 'L2_reg': 3.5682705078125,\n",
       " 'dropout': 0.1079609375,\n",
       " 'n_in': 11.0484697265625}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train a network based on opt_params on training data and save the model and weights (previous sections used cross-validation to find hyper-parameters, weights could not be saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS=4000\n",
    "hyperparams = {\n",
    "    'batch_norm': True,\n",
    "    'activation': 'rectify',\n",
    "    'standardize': False,\n",
    "    'n_in':xtrain.shape[1]\n",
    "}\n",
    "\n",
    "hyperparams.update(opt_params)\n",
    "\n",
    "if 'num_layers' in hyperparams and 'num_nodes' in hyperparams:\n",
    "    hyperparams['hidden_layers_sizes'] = [int(hyperparams['num_nodes'])] * int(hyperparams['num_layers'])\n",
    "    del hyperparams['num_layers']\n",
    "    del hyperparams['num_nodes']\n",
    "\n",
    "if 'learning_rate' in hyperparams:\n",
    "    hyperparams['learning_rate'] = 10 ** hyperparams['learning_rate']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standardizing\n",
    "#trainsub_mean = xtrainsub.mean(axis = 0)\n",
    "#trainsub_std = xtrainsub.std(axis = 0)\n",
    "#xtrainsub = (xtrainsub - trainsub_mean) / trainsub_std\n",
    "\n",
    "trainsub_data=format_to_deepsurv(xtrainsub, ytrainsub)\n",
    "\n",
    "#valsub_mean = xvalsub.mean(axis = 0)\n",
    "#valsub_std = xvalsub.std(axis = 0)\n",
    "#xvalsub = (xvalsub - valsub_mean) / valsub_std\n",
    "\n",
    "valsub_data=format_to_deepsurv(xvalsub, yvalsub)\n",
    "\n",
    "\n",
    "network = deep_surv.DeepSurv(**hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = network.train(trainsub_data,valsub_data, n_epochs = NUM_EPOCHS, update_fn = lasagne.updates.sgd, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.get_concordance_index(xvalsub,yvalsub[:,1],yvalsub[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply the trained network on test set and check the feature importance for generalization using  [permutation importance](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=test.iloc[:,1:-1].columns\n",
    "def score(X, y):\n",
    "    X=pd.DataFrame(X)\n",
    "    X.columns=colnames\n",
    "    data=X\n",
    "    data['Wait Time (s)']=y.values\n",
    "    data['E']=1\n",
    "    test = dataframe_to_deepsurv_ds(data, event_col = 'E', time_col= 'Wait Time (s)')\n",
    "    xtest=test['x']\n",
    "    xtest = (xtest - trainsub_mean) / trainsub_std              \n",
    "    etest=test['e']\n",
    "    ttest=test['t']\n",
    "    ytest = np.column_stack((etest, ttest))\n",
    "    valid_data = format_to_deepsurv(xtest, ytest)               #fix: network is trained again on test data\n",
    "    ci=network.get_concordance_index(**valid_data)\n",
    "    return ci\n",
    "\n",
    "\n",
    "st=time.time()\n",
    "\n",
    "base_score, score_decreases = get_score_importances(score, test.iloc[:,1:-1].values, test.iloc[:,0])\n",
    "                                                    #,columns_to_shuffle=range(0,2))\n",
    "f=time.time()\n",
    "\n",
    "feature_importances_mean = np.mean(score_decreases, axis=0)\n",
    "feature_importances_std = np.std(score_decreases, axis=0)\n",
    "\n",
    "perimportance=pd.DataFrame(data=feature_importances_mean,index=colnames,columns=['mean'])\n",
    "perimportance['std']=feature_importances_std\n",
    "\n",
    "\n",
    "\n",
    "perimportance=perimportance.sort_values(by=['mean'])\n",
    "\n",
    "\n",
    "\n",
    "def plot_feature_importances(imp):\n",
    "    plt.figure(figsize=(16,12))\n",
    "    n_features = imp.shape[0]\n",
    "    plt.barh(range(n_features), perimportance.iloc[:,0].values, align='center')\n",
    "    plt.yticks(np.arange(n_features), colnames)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "plot_feature_importances(perimportance)\n",
    "#plt.savefig('Decision Tree feature_importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCtrain.iloc[:,1:-1].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Shap for feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using train set for interpretability\n",
    "dfxtrainsub=pd.DataFrame(xtrain)\n",
    "dfxtrainsub.columns=NCtrain.iloc[:,1:-1].columns\n",
    "\n",
    "#using zeros as background data\n",
    "backgrounddata=pd.DataFrame(np.zeros(32)).T         \n",
    "backgrounddata.columns=NCtrain.iloc[:,1:-1].columns\n",
    "\n",
    "explainer = shap.KernelExplainer(network.predict_risk,backgrounddata)\n",
    "shap_values = explainer.shap_values(dfxtrainsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rework=pd.DataFrame(shap_values[0])\n",
    "rework.columns=features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reworkclean=rework.drop(columns=['One Way Road', 'Two way with Median Road', 'Night Time', 'Age between 18 - 24',\n",
    "    'Employed Person',\n",
    "       'Student', 'Owns a Driving License', 'Main Mode: Car',\n",
    "      'Main Mode: Walking', 'Sometimes Walks to Work',\n",
    "       'Always Walks to Work', 'Sometimes Walks for shopping',\n",
    "       'Speed Limit is Low', 'Speed Limit is high',\n",
    "       'Minimum Gap is Low',\n",
    "       'Mean Arrival Rate is Low', 'Does not own a car',\n",
    "       'Has more than one car'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reworkclean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reworkclean.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['Snowy Weather', 'Age between 25 - 29', 'Age between 30 - 39',\n",
    "       'Gender: Female', 'Main Mode: Public Transit',\n",
    "       'Always Walks for shopping', 'Has VR experinece', 'Lane Width is short',\n",
    "       'Lane Width is long', 'Minimum Gap is High',\n",
    "       'Mean Arrival Rate is High', 'Fully Automated Condition',\n",
    "       'Mixed Automated Condition', 'Age is over 50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=shap.summary_plot(reworkclean.values, features,max_display=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(reworkclean.values, features,max_display=32,show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "shap.summary_plot(reworkclean.values, features,max_display=32,show=False)\n",
    "pl.savefig('shap.png',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_df=pd.DataFrame(shap_values[0])\n",
    "shap_df.columns=NCtrain.iloc[:,1:-1].columns\n",
    "\n",
    "mean=shap_df[shap_df!=0].mean()              #mean of shap values for each feature (non-zeros only\n",
    "\n",
    "nonzeros=shap_df.astype(bool).sum(axis=0)        #count of non-zeros shap values for each feature\n",
    "\n",
    "std=shap_df[shap_df!=0].std()                #standard deviation of shap values for each feature\n",
    "\n",
    "featuresshap=pd.DataFrame()\n",
    "\n",
    "featuresshap['count1']=nonzeros\n",
    "featuresshap['bg0mean']=mean                 #bg0: zeros set as background data\n",
    "\n",
    "featuresshap['bg0std']=std\n",
    "\n",
    "featuresshap['bg0absmean']=abs(mean)\n",
    "\n",
    "featuresshap.sort_values(by=['bg0absmean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using ones as background data\n",
    "backgrounddata2=pd.DataFrame(np.ones(42)).T         \n",
    "backgrounddata2.columns=NCtrain.iloc[:,1:-1].columns\n",
    "\n",
    "explainer2 = shap.KernelExplainer(network.predict_risk,backgrounddata2)\n",
    "shap_values2 = explainer2.shap_values(dfxtrainsub)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values2[0], dfxtrainsub,max_display=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values2=pd.DataFrame(shap_values2[0])\n",
    "shap_values2.columns=NCtrain.iloc[:,1:-1].columns\n",
    "\n",
    "mean2=shap_values2[shap_values2!=0].mean()              #mean of shap values for each feature (non-zeros only\n",
    "\n",
    "std2=shap_values2[shap_values2!=0].std()                #standard deviation of shap values for each feature\n",
    "\n",
    "featuresshap['bg1mean']=mean2                           #bg1: ones set as background data\n",
    "\n",
    "featuresshap['bg1std']=std2\n",
    "\n",
    "featuresshap['bg1absmean']=abs(mean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresshap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
