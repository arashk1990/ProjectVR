{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "\n",
    "#sys.path.append('/home/arash/VRdataCleaning/DeepSurv/')\n",
    "\n",
    "import importlib\n",
    "import deepsurv\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "import argparse\n",
    "import uuid\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lasagne\n",
    "import optunity\n",
    "\n",
    "import logging\n",
    "from logging import handlers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "importlib.reload(deepsurv)\n",
    "\n",
    "from deepsurv import deep_surv, utils, viz\n",
    "\n",
    "from deepsurv.deepsurv_logger import DeepSurvLogger, TensorboardLogger\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "import shap  # package used to calculate Shap values\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data: \n",
    "#### xtrain: 80% of all data, devided into xtrainsub & xvalsub (80 and 20%) \n",
    "#### xtest: 20% of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/xtrain', 'rb') as f:\n",
    "    xtrain=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/ytrain', 'rb') as f:\n",
    "    ytrain=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/xtest', 'rb') as f:\n",
    "    xtest=pickle.load(f)\n",
    "\n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/ytest', 'rb') as f:\n",
    "    ytest=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/xtrainsub', 'rb') as f:\n",
    "    xtrainsub=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/ytrainsub', 'rb') as f:\n",
    "    ytrainsub=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/xvalsub', 'rb') as f:\n",
    "    xvalsub=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/yvalsub', 'rb') as f:\n",
    "    yvalsub=pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/nctrain', 'rb') as f:\n",
    "    NCtrain=pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/ProjectVR/cleaneddata/deepwaitdata/nctest', 'rb') as f:\n",
    "    NCtest=pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logger(logdir):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    format = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "    \n",
    "    # Print to Stdout\n",
    "    ch = logging.StreamHandler(sys.stdout)\n",
    "    ch.setFormatter(format)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "    # Print to Log file\n",
    "    fh = logging.FileHandler(os.path.join(logdir, 'log_' + str(uuid.uuid4())))\n",
    "    fh.setFormatter(format)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "    return logger\n",
    "\n",
    "def format_to_deepsurv(x, y):\n",
    "    return {\n",
    "        'x': x,\n",
    "        'e': y[:,0].astype(np.int32),\n",
    "        't': y[:,1].astype(np.float32)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_box_constraints(file):\n",
    "    with open(file, 'rb') as fp:\n",
    "        return json.loads(fp.read())\n",
    "\n",
    "def save_call_log(file, call_log):\n",
    "    with open(file, 'wb') as fp:\n",
    "        pickle.dump(call_log, fp)\n",
    "\n",
    "def get_objective_function(num_epochs, logdir, update_fn = lasagne.updates.sgd):\n",
    "    '''\n",
    "    Returns the function for Optunity to optimize. The function returned by get_objective_function\n",
    "    takes the parameters: x_train, y_train, x_test, and y_test, and any additional kwargs to \n",
    "    use as hyper-parameters.\n",
    "\n",
    "    The objective function runs a DeepSurv model on the training data and evaluates it against the\n",
    "    a validation set. The result of the function call is the validation concordance index \n",
    "    (which Optunity tries to optimize)\n",
    "    '''\n",
    "    def format_to_deepsurv(x, y):\n",
    "        return {\n",
    "            'x': x,\n",
    "            'e': y[:,0].astype(np.int32),\n",
    "            't': y[:,1].astype(np.float32)\n",
    "        }\n",
    "\n",
    "    def get_hyperparams(x,params):\n",
    "        hyperparams = {\n",
    "            'batch_norm': False,\n",
    "            'activation': 'rectify',\n",
    "            'standardize': True,\n",
    "            'n_in':x.shape[1]\n",
    "        }\n",
    "\n",
    "        if 'num_layers' in params and 'num_nodes' in params:\n",
    "            params['hidden_layers_sizes'] = [int(params['num_nodes'])] * int(params['num_layers'])\n",
    "            del params['num_layers']\n",
    "            del params['num_nodes']\n",
    "\n",
    "        if 'learning_rate' in params:\n",
    "            params['learning_rate'] = 10 ** params['learning_rate']\n",
    "            \n",
    "            \n",
    "\n",
    "        hyperparams.update(params)\n",
    "        return hyperparams\n",
    "\n",
    "    def train_deepsurv(x_train,y_train,x_test,y_test,\n",
    "        **kwargs):\n",
    "        hyperparams = get_hyperparams(x_train,kwargs)\n",
    "     \n",
    "        \n",
    "        # Standardize the datasets\n",
    "        train_mean = x_train.mean(axis = 0)\n",
    "        train_std = x_train.std(axis = 0)\n",
    "\n",
    "        x_train = (x_train - train_mean) / train_std\n",
    "        x_test = (x_test - train_mean) / train_std\n",
    "\n",
    "        train_data = format_to_deepsurv(x_train, y_train)\n",
    "        valid_data = format_to_deepsurv(x_test, y_test)\n",
    "\n",
    "        \n",
    "\n",
    "        # Set up Tensorboard loggers\n",
    "        model_id = str(hash(str(hyperparams)))\n",
    "        run_id = model_id + '_' + str(uuid.uuid4())\n",
    "        logger = TensorboardLogger('hyperparam_search', \n",
    "            os.path.join(logdir,\"tensor_logs\", model_id, run_id))\n",
    "\n",
    "        network = deep_surv.DeepSurv(**hyperparams)\n",
    "        metrics = network.train(train_data, n_epochs = num_epochs, logger=logger, \n",
    "            update_fn = update_fn, verbose = False)\n",
    "\n",
    "        result = network.get_concordance_index(**valid_data)\n",
    "        main_logger.info('Run id: %s | %s | C-Index: %f | Train Loss %f' % (run_id, str(hyperparams), result, metrics['loss'][-1][1]))\n",
    "        return result\n",
    "\n",
    "    return train_deepsurv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Find the optimal hyper-parameters using training data and save them in opt_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "NUM_FOLDS = 8\n",
    "logdir='/home/arash/ProjectVR/logs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_logger = load_logger(logdir)\n",
    "\n",
    "\n",
    "#    main_logger.debug('Loading dataset: ' + args.dataset)\n",
    "box_constraints = load_box_constraints('/home/arash/ProjectVR/box_constraints.0.json')\n",
    "\n",
    "76\n",
    "opt_fxn = get_objective_function(NUM_EPOCHS, logdir, \n",
    "                                 utils.get_optimizer_from_str('adam'))\n",
    "\n",
    "opt_fxn = optunity.cross_validated(x=xtrain, y=ytrain, num_folds=NUM_FOLDS)(opt_fxn)\n",
    "\n",
    "\n",
    "opt_params, call_log, _ = optunity.maximize(opt_fxn, num_evals=20,\n",
    "        solver_name='sobol',\n",
    "        **box_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train a network based on opt_params on training data and save the model and weights (previous sections used cross-validation to find hyper-parameters, weights could not be saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS=2000\n",
    "hyperparams = {\n",
    "    'batch_norm': True,\n",
    "    'activation': 'rectify',\n",
    "    'standardize': False,\n",
    "    'n_in':xtrain.shape[1]\n",
    "}\n",
    "\n",
    "hyperparams.update(opt_params)\n",
    "\n",
    "if 'num_layers' in hyperparams and 'num_nodes' in hyperparams:\n",
    "    hyperparams['hidden_layers_sizes'] = [int(hyperparams['num_nodes'])] * int(hyperparams['num_layers'])\n",
    "    del hyperparams['num_layers']\n",
    "    del hyperparams['num_nodes']\n",
    "\n",
    "if 'learning_rate' in hyperparams:\n",
    "    hyperparams['learning_rate'] = 10 ** hyperparams['learning_rate']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standardizing\n",
    "#trainsub_mean = xtrainsub.mean(axis = 0)\n",
    "#trainsub_std = xtrainsub.std(axis = 0)\n",
    "#xtrainsub = (xtrainsub - trainsub_mean) / trainsub_std\n",
    "\n",
    "trainsub_data=format_to_deepsurv(xtrainsub, ytrainsub)\n",
    "\n",
    "#valsub_mean = xvalsub.mean(axis = 0)\n",
    "#valsub_std = xvalsub.std(axis = 0)\n",
    "#xvalsub = (xvalsub - valsub_mean) / valsub_std\n",
    "\n",
    "valsub_data=format_to_deepsurv(xvalsub, yvalsub)\n",
    "\n",
    "\n",
    "network = deep_surv.DeepSurv(**hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = network.train(trainsub_data,valsub_data, n_epochs = NUM_EPOCHS, update_fn = lasagne.updates.sgd, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.get_concordance_index(xtrainsub,ytrainsub[:,1],ytrainsub[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply the trained network on test set and check the feature importance for generalization using  [permutation importance](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=test.iloc[:,1:-1].columns\n",
    "def score(X, y):\n",
    "    X=pd.DataFrame(X)\n",
    "    X.columns=colnames\n",
    "    data=X\n",
    "    data['Wait Time (s)']=y.values\n",
    "    data['E']=1\n",
    "    test = dataframe_to_deepsurv_ds(data, event_col = 'E', time_col= 'Wait Time (s)')\n",
    "    xtest=test['x']\n",
    "    xtest = (xtest - trainsub_mean) / trainsub_std              \n",
    "    etest=test['e']\n",
    "    ttest=test['t']\n",
    "    ytest = np.column_stack((etest, ttest))\n",
    "    valid_data = format_to_deepsurv(xtest, ytest)               #fix: network is trained again on test data\n",
    "    ci=network.get_concordance_index(**valid_data)\n",
    "    return ci\n",
    "\n",
    "\n",
    "st=time.time()\n",
    "\n",
    "base_score, score_decreases = get_score_importances(score, test.iloc[:,1:-1].values, test.iloc[:,0])\n",
    "                                                    #,columns_to_shuffle=range(0,2))\n",
    "f=time.time()\n",
    "\n",
    "feature_importances_mean = np.mean(score_decreases, axis=0)\n",
    "feature_importances_std = np.std(score_decreases, axis=0)\n",
    "\n",
    "perimportance=pd.DataFrame(data=feature_importances_mean,index=colnames,columns=['mean'])\n",
    "perimportance['std']=feature_importances_std\n",
    "\n",
    "\n",
    "\n",
    "perimportance=perimportance.sort_values(by=['mean'])\n",
    "\n",
    "\n",
    "\n",
    "def plot_feature_importances(imp):\n",
    "    plt.figure(figsize=(16,12))\n",
    "    n_features = imp.shape[0]\n",
    "    plt.barh(range(n_features), perimportance.iloc[:,0].values, align='center')\n",
    "    plt.yticks(np.arange(n_features), colnames)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "plot_feature_importances(perimportance)\n",
    "#plt.savefig('Decision Tree feature_importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Shap for feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using train set for interpretability\n",
    "dfxtrainsub=pd.DataFrame(xtrainsub)\n",
    "dfxtrainsub.columns=NCtrain.iloc[:,1:-1].columns\n",
    "\n",
    "#using zeros as background data\n",
    "backgrounddata=pd.DataFrame(np.zeros(42)).T         \n",
    "backgrounddata.columns=NCtrain.iloc[:,1:-1].columns\n",
    "\n",
    "explainer = shap.KernelExplainer(network.predict_risk,backgrounddata)\n",
    "shap_values = explainer.shap_values(dfxtrainsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[0], dfxtrainsub,max_display=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_df=pd.DataFrame(shap_values[0])\n",
    "shap_df.columns=NCtrain.iloc[:,1:-1].columns\n",
    "\n",
    "mean=shap_df[shap_df!=0].mean()              #mean of shap values for each feature (non-zeros only\n",
    "\n",
    "nonzeros=shap_df.astype(bool).sum(axis=0)        #count of non-zeros shap values for each feature\n",
    "\n",
    "std=shap_df[shap_df!=0].std()                #standard deviation of shap values for each feature\n",
    "\n",
    "featuresshap=pd.DataFrame()\n",
    "\n",
    "featuresshap['count1']=nonzeros\n",
    "featuresshap['bg0mean']=mean                 #bg0: zeros set as background data\n",
    "\n",
    "featuresshap['bg0std']=std\n",
    "\n",
    "featuresshap['bg0absmean']=abs(mean)\n",
    "\n",
    "featuresshap.sort_values(by=['bg0absmean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using ones as background data\n",
    "backgrounddata2=pd.DataFrame(np.ones(42)).T         \n",
    "backgrounddata2.columns=NCtrain.iloc[:,1:-1].columns\n",
    "\n",
    "explainer2 = shap.KernelExplainer(network.predict_risk,backgrounddata2)\n",
    "shap_values2 = explainer2.shap_values(dfxtrainsub)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values2[0], dfxtrainsub,max_display=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values2=pd.DataFrame(shap_values2[0])\n",
    "shap_values2.columns=NCtrain.iloc[:,1:-1].columns\n",
    "\n",
    "mean2=shap_values2[shap_values2!=0].mean()              #mean of shap values for each feature (non-zeros only\n",
    "\n",
    "std2=shap_values2[shap_values2!=0].std()                #standard deviation of shap values for each feature\n",
    "\n",
    "featuresshap['bg1mean']=mean2                           #bg1: ones set as background data\n",
    "\n",
    "featuresshap['bg1std']=std2\n",
    "\n",
    "featuresshap['bg1absmean']=abs(mean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresshap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer3.shap_values(NCtrain.iloc[2,1:-1])\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer3.expected_value[0], shap_values[0], NCtrain.iloc[2,1:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
