{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "import time\n",
    "import glob,os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for LSTM: project: pedestrian trajecory prediction based on head orientation, previous trajectory and distance to cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/arash/VRdataCleaning/cleaneddata/ALLDATA', 'rb') as f:\n",
    "    ALLDATA = pickle.load(f)\n",
    "    \n",
    "with open('/home/arash/VRdataCleaning/cleaneddata/allexperiments', 'rb') as f:\n",
    "    experiments = pickle.load(f)\n",
    "\n",
    "ALLDATAfortraj=ALLDATA.loc[-ALLDATA['starttime'].isin(['Err1','Err2','Err3','Err4','Err5'])]\n",
    "\n",
    "# limit trajectory records to a time frame starting from 1 sec before cross to the end.\n",
    "trajectory=[]\n",
    "for n in range(len(experiments)):    \n",
    "    if len(ALLDATAfortraj[ALLDATAfortraj['File']==experiments[n]['filename'][0]]['starttime'])>0:\n",
    "        df=experiments[n][experiments[n]['timeelaspsed'].astype(float)>\n",
    "                          (float(ALLDATAfortraj[ALLDATAfortraj['File']==\n",
    "                                                experiments[n]['filename'][0]]['starttime'])-1)]\n",
    "        df=df.drop(columns=['timehr','timemin','timesec',])\n",
    "        trajectory.append(df)\n",
    "\n",
    "# build time series data from pedestrian movements\n",
    "userXtraj=[]\n",
    "usero1traj=[]\n",
    "usero2traj=[]\n",
    "usero3traj=[]\n",
    "userdisttraj=[]\n",
    "\n",
    "for i in range(len(trajectory)):\n",
    "    if len(trajectory[i][(trajectory[i]['status']=='u ') & (trajectory[i]['x'].astype(float)>650)])>0:\n",
    "        oneroad=int(DesignID[DesignID['Card ID']==       #to see if the scenario is one road\n",
    "                             int(ALLDATAfortraj[ALLDATAfortraj['File']\n",
    "                                                ==trajectory[i].iloc[0,-1]]['Scenario'])]['Road Type_One way'])\n",
    "        xarr=trajectory[i][(trajectory[i]['status']=='u ') & \n",
    "                           (trajectory[i]['x'].astype(float)>650)]['x'].values.astype(float)    \n",
    "        # 650 threshold is the approximate x coordinate for the middle of the road, user trajectory in the end of exp are removed\n",
    "        \n",
    "        headarr1=trajectory[i][(trajectory[i]['status']=='u ') & \n",
    "                           (trajectory[i]['x'].astype(float)>650)]['o1'].values.astype(float)    #head orientation 1\n",
    "        headarr2=trajectory[i][(trajectory[i]['status']=='u ') & \n",
    "                           (trajectory[i]['x'].astype(float)>650)]['o2'].values.astype(float)    #head orientation 2\n",
    "        headarr3=trajectory[i][(trajectory[i]['status']=='u ') & \n",
    "                           (trajectory[i]['x'].astype(float)>650)]['o3'].values.astype(float)    #head orientation 3\n",
    "        \n",
    "        firstpedindex=trajectory[i][(trajectory[i]['status']=='u ') & \n",
    "                           (trajectory[i]['x'].astype(float)>650)].index[0]  #index for pedestrian 1st appearance\n",
    "        \n",
    "        pedindex=trajectory[i][(trajectory[i]['status']=='u ') & \n",
    "                           (trajectory[i]['x'].astype(float)>650)].index-firstpedindex   #convert index to new format\n",
    "        \n",
    "        dist=[]\n",
    "        for index, item in enumerate(pedindex):      #distance at every moment\n",
    "            if index>0:\n",
    "                bwped=trajectory[i].iloc[pedindex[index-1]:pedindex[index],:]     #data from between peds\n",
    "                if len(bwped[bwped['status'].str.contains('L',na=False)].index)==0:    #if no cars on left lane at the moment\n",
    "                    distance=100\n",
    "                else:            \n",
    "                    if oneroad==0:\n",
    "                        if len((bwped[(bwped['x'].astype(float)>650) & (bwped['status'] !='u ') &\n",
    "                                      (bwped['y'].astype(float)> bwped.iloc[0,1])]['y']))==0:     \n",
    "                            #check if any car that has not passed exists  \n",
    "                            #1st cond: car in left lane, 2nd not a user data, 3rd: car has not passed ped yet differs for oneway and two-way roads\n",
    "                            distance=100\n",
    "                        else:\n",
    "                            distance=min(bwped[(bwped['x'].astype(float)>650) & (bwped['status'] !='u ') &\n",
    "                                               (bwped['y'].astype(float)> bwped.iloc[0,1])]['y']) - bwped.iloc[0,1] \n",
    "                    else:   #one-way roads\n",
    "                        if len((bwped[(bwped['x'].astype(float)>650) & (bwped['status'] !='u ') &\n",
    "                                      (bwped['y'].astype(float)< bwped.iloc[0,1])]['y']))==0:     #check if any car that has not passed exists  \n",
    "                            #1st cond: car in left lane, 2nd not a user data, 3rd: car has not passed ped yet differs for oneway and two-way roads\n",
    "                            distance = 100\n",
    "                        else:\n",
    "                            distance = bwped.iloc[0,1] -\n",
    "                            max(bwped[(bwped['x'].astype(float)>650)\n",
    "                                      & (bwped['status'] !='u ') & (bwped['y'].astype(float)< \n",
    "                                                                    bwped.iloc[0,1])]['y']) \n",
    "                dist.append(distance)\n",
    "\n",
    "\n",
    "        userXtraj.append(xarr)\n",
    "        usero1traj.append(headarr1)\n",
    "        usero2traj.append(headarr2)\n",
    "        usero3traj.append(headarr3)\n",
    "        userdisttraj.append(dist)\n",
    "\n",
    "#Convert tractory files to readable format for lstm. \n",
    "\n",
    "def sampleinput(userXtraj,usero1traj,usero2traj,usero3traj,userdisttraj, inputportion):\n",
    "    X, o1, o2, o3, dist, y = list(), list(),list(), list(),list(), list()\n",
    "    for i in range(len(userXtraj)):\n",
    "        # find the end of this pattern\n",
    "        xdistancecovered=max(userXtraj[i])-min(userXtraj[i])     #total distance covered by user from start to end of the expmeriment\n",
    "        xinput=xdistancecovered*inputportion                    #distance that is used as input to the model                   \n",
    "        breakpoint=min(userXtraj[i])+xinput\n",
    "        n_steps=len([x for x in userXtraj[i] if x<breakpoint])\n",
    "        \n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = userXtraj[i][0:n_steps], userXtraj[i][n_steps:]\n",
    "        seq_o1=usero1traj[i][0:n_steps]\n",
    "        seq_o2=usero2traj[i][0:n_steps]\n",
    "        seq_o3=usero3traj[i][0:n_steps]\n",
    "        seq_dist=userdisttraj[i][0:n_steps]\n",
    "\n",
    "        X.append(seq_x)\n",
    "        o1.append(seq_o1)\n",
    "        o2.append(seq_o2)\n",
    "        o3.append(seq_o3)\n",
    "        dist.append(seq_dist)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    return X,o1,o2,o3 ,dist, y\n",
    "\n",
    "inputportion = 0.5\n",
    "# convert into input/output\n",
    "X, o1, o2, o3, dist, y = sampleinput(userXtraj,usero1traj, usero2traj, usero3traj,userdisttraj, inputportion)\n",
    "\n",
    "#check for ouliers\n",
    "dur=[]\n",
    "for i in range(len(X)):\n",
    "    x=X[i].shape[0]+y[i].shape[0]\n",
    "    dur.append(x)\n",
    "\n",
    "dur=pd.DataFrame(dur,columns=['duration'])\n",
    "\n",
    "dur.describe()\n",
    "\n",
    "plt.hist(dur.iloc[:,0])#.nlargest(10,'duration')\n",
    "\n",
    "#indices of experiments when it takes more than ~15 seconds  to cross. 109 rows out of total 3424 removed\n",
    "out=dur[dur['duration']>150].index\n",
    "\n",
    "\n",
    "\n",
    "for i in sorted(out,reverse=True):\n",
    "    del X[i]\n",
    "    del o1[i]\n",
    "    del o2[i]\n",
    "    del o3[i]\n",
    "    del dist[i]\n",
    "    del y[i]\n",
    "\n",
    "# converting list to array\n",
    "X=np.array(X)\n",
    "o1=np.array(o1)\n",
    "o2=np.array(o2)\n",
    "o3=np.array(o3)\n",
    "dist=np.array(dist)\n",
    "y=np.array(y)\n",
    "\n",
    "Xpadded = pad_sequences(X, dtype='float32')       #padding sequences to have same length by adding 0s\n",
    "o1padded = pad_sequences(o1,dtype='float32')\n",
    "o2padded = pad_sequences(o2,dtype='float32')\n",
    "o3padded = pad_sequences(o3,dtype='float32')\n",
    "distpadded = pad_sequences(dist,dtype='float32')\n",
    "ypadded = pad_sequences(y, padding='post',dtype='float32')\n",
    "\n",
    "inputseq=[]\n",
    "for i in range(Xpadded.shape[0]):\n",
    "    mrg_input=np.transpose(np.vstack((Xpadded[i],o1padded[i],o2padded[i],o3padded[i],distpadded[i])))\n",
    "    inputseq.append(mrg_input)\n",
    "    \n",
    "\n",
    "inputseq=np.array(inputseq)\n",
    "\n",
    "allseqdata=[inputseq,ypadded]     #save all the sequence data to file\n",
    "\n",
    "\n",
    "# save to pickle\n",
    "with open('seqdata', 'wb') as f:\n",
    "    pickle.dump(allseqdata, f)\n",
    "\n",
    "#####not use scaled measures for now\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "Xscaled = scaler.fit_transform(Xpadded)\n",
    "\n",
    "yscaled = scaler.fit_transform(ypadded)\n",
    "\n",
    "o1scaled = scaler.fit_transform(o1padded)\n",
    "o2scaled = scaler.fit_transform(o2padded)\n",
    "o3scaled = scaler.fit_transform(o3padded)\n",
    "distscaled = scaler.fit_transform(distpadded)\n",
    "\n",
    "\n",
    "#covedrting to an array shaped: samples * n_steps * features\n",
    "inputseq=[]\n",
    "for i in range(Xpadded.shape[0]):\n",
    "    mrg_input=np.transpose(np.vstack((Xpadded[i],o1padded[i],o2padded[i],o3padded[i],distpadded[i])))\n",
    "    inputseq.append(mrg_input)\n",
    "    \n",
    "\n",
    "inputseq=np.array(inputseq)\n",
    "\n",
    "\n",
    "\n",
    "#check if data is float:\n",
    "ypadded.dtype\n",
    "inputseq.dtype\n",
    "\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = inputseq.shape[2]\n",
    "n_steps_in=inputseq.shape[1]\n",
    "n_steps_out=ypadded.shape[1]\n",
    "\n",
    "\n",
    "# seperate validation data and test set\n",
    "import random\n",
    "tst=0.2\n",
    "val=0.2\n",
    "tstsize = int(np.floor(len(inputseq) * tst))\n",
    "valsize = int(np.floor(len(inputseq) * val))\n",
    "\n",
    "\n",
    "\n",
    "tstlabel=[]\n",
    "for i in range(tstsize):\n",
    "    temp = random.randint(0,inputseq.shape[0]+1)\n",
    "    tstlabel.append(temp)\n",
    "\n",
    "Xtest=inputseq[tstlabel]\n",
    "ytest=ypadded[tstlabel]\n",
    "\n",
    "\n",
    "\n",
    "trnlabel=[i for i in range(inputseq.shape[0]) if i not in tstlabel]\n",
    "trnsize=len(trnlabel)\n",
    "\n",
    "Xtrain=inputseq[trnlabel]\n",
    "ytrain=ypadded[trnlabel]\n",
    "\n",
    "\n",
    "\n",
    "vallabel=[]\n",
    "for i in range(valsize):\n",
    "    temp = trnlabel[random.randint(0,trnsize+1)]\n",
    "    vallabel.append(temp)\n",
    "\n",
    "Xval=inputseq[vallabel]\n",
    "yval=ypadded[vallabel]\n",
    "\n",
    "trainlabel=[i for i in range(Xtrain.shape[0]) if i not in [vallabel]]\n",
    "Xtrain=Xtrain[trainlabel]\n",
    "ytrain=ytrain[trainlabel]\n",
    "\n",
    "\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history=model.fit(Xtrain, ytrain,\n",
    "                  epochs=200, verbose=1,batch_size=72,\n",
    "                  validation_data=(Xval, yval))\n",
    "                  \n",
    "\n",
    "\n",
    "\n",
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "#pyplot.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(Xval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
